{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp080"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp078のxgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import pathlib\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Cfg:\n",
    "    mode = \"local_cv\" # \"local_cv\" or \"kaggle_inf\" \n",
    "    exp_name = \"exp080\"\n",
    "    input_dir = \"/mnt/predict-student-performance-from-game-play/input/\"\n",
    "    output_dir = \"/mnt/predict-student-performance-from-game-play/output/\"\n",
    "    prep_dir = \"/mnt/predict-student-performance-from-game-play/prep/\"\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    best_threshold = 0.630 # local_cvの結果を入れる\n",
    "    base_exp = None # 特徴量重要度を使う元のexp\n",
    "    n_features = 500 # 特徴量削減の数\n",
    "cfg = Cfg()\n",
    "\n",
    "if cfg.mode == \"local_cv\":\n",
    "    os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name, \"cache\"), exist_ok=True)\n",
    "\n",
    "elif cfg.mode == \"kaggle_inf\":\n",
    "    import jo_wilder_310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'objective' : 'binary:logistic',\n",
    "        'tree_method': 'gpu_hist', # v29 gpuで学習 hist or gpu_hist\n",
    "        'eval_metric':'logloss',\n",
    "        'learning_rate': 0.02, # v29 0.05->0.02\n",
    "        'alpha': 8,\n",
    "        'max_depth': 4,\n",
    "        'n_estimators': 100000, # 最大学習サイクル数。early_stopping使用時は大きな値を入力 100000\n",
    "        # v17 50 -> 200\n",
    "        'early_stopping_rounds': 200,\n",
    "        'subsample':0.8,\n",
    "        'colsample_bytree': 0.4,\n",
    "        'seed': cfg.seed\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_group_list = ['0-4', '5-12', '13-22']\n",
    "level_group_map = {\n",
    "    \"q1\":\"0-4\", \"q2\":\"0-4\", \"q3\":\"0-4\",\n",
    "    \"q4\":\"5-12\", \"q5\":\"5-12\", \"q6\":\"5-12\", \"q7\":\"5-12\", \"q8\":\"5-12\", \"q9\":\"5-12\", \"q10\":\"5-12\", \"q11\":\"5-12\", \"q12\":\"5-12\", \"q13\":\"5-12\",\n",
    "    \"q14\":\"13-22\", \"q15\":\"13-22\", \"q16\":\"13-22\", \"q17\":\"13-22\", \"q18\":\"13-22\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.mode == \"local_cv\":\n",
    "    with open(cfg.prep_dir + 'cat_col_lists_v2.pkl', 'rb') as f:\n",
    "        cat_col_lists = pickle.load(f) \n",
    "\n",
    "elif cfg.mode == \"kaggle_inf\":\n",
    "    with open(\"/kaggle/input/psp-cat-col-lists/cat_col_lists_v2.pkl\", 'rb') as f:\n",
    "        cat_col_lists = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels_df_train(labels_):\n",
    "    \"\"\"\n",
    "    labelsデータを整形する\n",
    "    \"\"\"\n",
    "    labels = labels_.copy()\n",
    "    labels[\"question\"] = labels[\"session_id\"].apply(lambda x: x.split(\"_\")[1].replace(\"q\", \"\")).astype(int)\n",
    "    labels[\"session_id\"] = labels[\"session_id\"].apply(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "\n",
    "    # trainの特徴量と結合するためにquestionに対応するlabel_groupを列として設けておく\n",
    "    labels[\"level_group\"] = \"\"\n",
    "    labels.loc[labels[\"question\"]<=3, \"level_group\"] = \"0-4\"\n",
    "    labels.loc[(labels[\"question\"]>=4)&(labels[\"question\"]<=13), \"level_group\"] = \"5-12\"\n",
    "    labels.loc[labels[\"question\"]>=14, \"level_group\"] = \"13-22\"\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def transform_labels_df_inf(labels_):\n",
    "    \"\"\"\n",
    "    labelsデータを整形する\n",
    "    \"\"\"\n",
    "    labels = labels_.copy()\n",
    "    labels[\"question\"] = labels[\"session_id\"].apply(lambda x: x.split(\"_\")[1].replace(\"q\", \"\")).astype(int)\n",
    "    labels[\"session_id\"] = labels[\"session_id\"].apply(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesTrain:\n",
    "    def __init__(self, sessions_df, labels):\n",
    "        self.sessions_df = sessions_df.sort_values([\"session_id\", \"level_group\", \"index\"], ignore_index=True)\n",
    "        self.features = self.sessions_df[[\"session_id\", \"level_group\"]].drop_duplicates().copy()\n",
    "        self.result = labels\n",
    "        self.group = sessions_df[\"level_group\"].values[0]\n",
    "\n",
    "    def _prep(self):\n",
    "        self.sessions_df[\"time_diff\"] = self.sessions_df[\"elapsed_time\"] - self.sessions_df.groupby([\"session_id\", \"level_group\"])[\"elapsed_time\"].shift(1)\n",
    "        self.sessions_df[\"time_diff\"] = np.where(self.sessions_df[\"time_diff\"]<0, 0, self.sessions_df[\"time_diff\"])\n",
    "        self.sessions_df[\"time_diff\"] = np.nan_to_num(self.sessions_df[\"time_diff\"], 0)\n",
    "        self.sessions_df[\"event_name+name\"] = self.sessions_df[\"event_name\"] + \"_\" + self.sessions_df[\"name\"]\n",
    "        self.sessions_df[\"event_name+room_fqid\"] = self.sessions_df[\"event_name\"] + \"_\" + self.sessions_df[\"room_fqid\"]\n",
    "        self.sessions_df[\"event_name+fqid\"] = self.sessions_df[\"event_name\"] + \"_\" + self.sessions_df[\"fqid\"]\n",
    "\n",
    "    def _total_record_cnt(self):\n",
    "        \"\"\"level_groupごとのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions_df.groupby([\"session_id\", \"level_group\"])[\"index\"].count().reset_index().rename(columns={\"index\":f\"{self.group}_record_cnt\"})\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _group_elapsed_time(self):\n",
    "        \"\"\"level_groupごと、epapsed_timeのmax - min（経過時間）\n",
    "        \"\"\"\n",
    "        add_features = self.sessions_df.groupby([\"session_id\", \"level_group\"])[\"elapsed_time\"].agg([max,min]).reset_index()\n",
    "        add_features[f\"{self.group}_group_elapsed_time\"] = add_features[\"max\"] - add_features[\"min\"]\n",
    "        add_features[f\"{self.group}_group_elapsed_time\"] = add_features[f\"{self.group}_group_elapsed_time\"].astype(np.float32)\n",
    "        add_features = add_features[[\"session_id\", \"level_group\", f\"{self.group}_group_elapsed_time\"]].copy()\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _cat_record_cnt(self, cat_col):\n",
    "        \"\"\"level_groupごと、各{cat}のレコード数\n",
    "        \"\"\"\n",
    "        cat_list = cat_col_lists[self.group][cat_col]\n",
    "        add_features = self.sessions_df.groupby([\"session_id\", \"level_group\", cat_col])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for cat in cat_list:\n",
    "            feat_name = f\"{self.group}_{cat_col}_{str(cat)}_record_cnt\"\n",
    "            tmp = add_features[add_features[cat_col]==cat][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": feat_name})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[feat_name] = self.features[feat_name].fillna(0).astype(int)\n",
    "            else:\n",
    "                self.features[feat_name] = int(0)\n",
    "\n",
    "    def _cat_col_nunique(self, cat_col):\n",
    "        \"\"\"level_groupごと、[col]のユニーク数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions_df.dropna(subset=[cat_col]).drop_duplicates([\"session_id\", \"level_group\", cat_col])\n",
    "        add_features = add_features.groupby([\"session_id\", \"level_group\"])[\"index\"].count().reset_index().rename(columns={\"index\":f\"{self.group}_{cat_col}_nunique\"})\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")        \n",
    "\n",
    "    def _agg_features(self, val_cols, aggs):\n",
    "        new_cols = [f\"{self.group}_{v}_{a}\" for v,a in itertools.product(val_cols, aggs)]\n",
    "        add_features = self.sessions_df.groupby([\"session_id\", \"level_group\"])[val_cols].agg(aggs).reset_index()\n",
    "        add_features.columns = [\"session_id\", \"level_group\"] + new_cols\n",
    "        add_features[new_cols] = add_features[new_cols].astype(np.float32)\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _cat_agg_features(self, val_cols, aggs, cat_col, not_use_cats=None):\n",
    "        add_features = self.sessions_df.groupby([\"session_id\", \"level_group\", cat_col])[val_cols].agg(aggs).reset_index()\n",
    "\n",
    "        if not_use_cats is not None:\n",
    "            cat_list = [c for c in cat_col_lists[self.group][cat_col] if c not in not_use_cats]\n",
    "        else:\n",
    "            cat_list = cat_col_lists[self.group][cat_col]\n",
    "\n",
    "        for cat in cat_list:\n",
    "            new_cols = [f\"{self.group}_{cat_col}_{cat}_{v}_{a}\" for v,a in itertools.product(val_cols, aggs)]\n",
    "            tmp = add_features[add_features[cat_col]==cat].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp.columns = [\"session_id\", \"level_group\", cat_col] + new_cols\n",
    "                tmp = tmp.drop(columns=[cat_col])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "            self.features[new_cols] = self.features[new_cols].astype(np.float32)\n",
    "\n",
    "    def _cat_change_cnt(self, cat_col):\n",
    "        \"\"\"cat_colの変化回数\n",
    "        \"\"\"\n",
    "        tmp = self.sessions_df[[\"session_id\", \"level_group\", cat_col]].copy()\n",
    "        tmp[cat_col] = tmp[cat_col].fillna(\"nan\")\n",
    "        tmp[f\"{self.group}_{cat_col}_change_cnt\"] = (tmp[cat_col] != tmp.groupby([\"session_id\", \"level_group\"])[cat_col].shift(1)).astype(int)\n",
    "        add_features = tmp.groupby([\"session_id\", \"level_group\"])[f\"{self.group}_{cat_col}_change_cnt\"].sum().reset_index()\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "\n",
    "    def _add_minigame_features(self, start_fqid, end_fqid):\n",
    "        game_name = start_fqid\n",
    "        dfs = []\n",
    "        for session_id in tqdm(self.sessions_df[\"session_id\"].unique()):\n",
    "            tmp = self.sessions_df[self.sessions_df[\"session_id\"]==session_id].copy()\n",
    "            start_indexes = tmp[(tmp[\"event_name\"]==\"navigate_click\")&(tmp[\"fqid\"]==start_fqid)][\"index\"].values\n",
    "            end_indexes = tmp[(tmp[\"event_name\"]==\"object_click\")&(tmp[\"fqid\"]==end_fqid)][\"index\"].values\n",
    "            if len(start_indexes) > 0:\n",
    "                start_index = start_indexes[0]\n",
    "            else:\n",
    "                start_index = np.nan\n",
    "            if len(end_indexes) > 0:\n",
    "                end_index = end_indexes[0]\n",
    "            else:\n",
    "                end_index = np.nan\n",
    "\n",
    "            if start_index < end_index:\n",
    "                mini_game_sessions = tmp[(tmp[\"index\"]>start_index)&(tmp[\"index\"]<=end_index)].copy()\n",
    "                record_cnt = len(mini_game_sessions)\n",
    "                total_duration = mini_game_sessions[\"time_diff\"].sum()\n",
    "                total_hover_duration = mini_game_sessions[\"hover_duration\"].sum()\n",
    "\n",
    "                hover_sessions = mini_game_sessions[mini_game_sessions[\"event_name\"]==\"object_hover\"].copy()\n",
    "                if len(hover_sessions) > 0:\n",
    "                    hover_cnt = len(hover_sessions)\n",
    "                else:\n",
    "                    hover_cnt = 0\n",
    "\n",
    "                click_sessions = mini_game_sessions[mini_game_sessions[\"event_name\"]==\"object_click\"].copy()\n",
    "                if len(click_sessions) > 0:\n",
    "                    click_cnt = len(click_sessions)\n",
    "                else:\n",
    "                    click_cnt = 0\n",
    "\n",
    "                feature_tmp = pd.DataFrame([[session_id, record_cnt, total_duration, total_hover_duration, hover_cnt, click_cnt]],\n",
    "                                            columns=[\"session_id\", f\"{self.group}_minigame_{game_name}_record_cnt\", f\"{self.group}_minigame_{game_name}_total_duration\", f\"{self.group}_minigame_{game_name}_total_hover_duration\",\n",
    "                                                    f\"{self.group}_minigame_{game_name}_hover_cnt\", f\"{self.group}_minigame_{game_name}_click_cnt\"]\n",
    "                                        )\n",
    "            else:\n",
    "                feature_tmp = pd.DataFrame([[session_id, 0, 0, 0, 0, 0]],\n",
    "                                            columns=[\"session_id\", f\"{self.group}_minigame_{game_name}_record_cnt\", f\"{self.group}_minigame_{game_name}_total_duration\", f\"{self.group}_minigame_{game_name}_total_hover_duration\",\n",
    "                                                    f\"{self.group}_minigame_{game_name}_hover_cnt\", f\"{self.group}_minigame_{game_name}_click_cnt\"]\n",
    "                                        )\n",
    "            dfs.append(feature_tmp)\n",
    "        add_features = pd.concat(dfs, ignore_index=True)\n",
    "        self.features = self.features.merge(add_features, on=\"session_id\", how=\"left\")\n",
    "\n",
    "\n",
    "    def get_train(self):\n",
    "        self._prep()\n",
    "        self._total_record_cnt()\n",
    "        self._group_elapsed_time()\n",
    "        self._cat_record_cnt(\"event_name\")\n",
    "        self._cat_record_cnt(\"name\")\n",
    "        self._cat_record_cnt(\"page\")\n",
    "        self._cat_record_cnt(\"level\")\n",
    "        self._cat_record_cnt(\"room_fqid\")\n",
    "        self._cat_record_cnt(\"fqid\")\n",
    "        self._cat_record_cnt(\"text_fqid\")\n",
    "        self._cat_record_cnt(\"event_name+name\")\n",
    "        self._cat_record_cnt(\"event_name+room_fqid\")\n",
    "        self._cat_record_cnt(\"event_name+fqid\")\n",
    "        self._cat_col_nunique(\"text\")\n",
    "        self._cat_col_nunique(\"text_fqid\")\n",
    "        self._cat_col_nunique(\"room_fqid\")\n",
    "        self._cat_col_nunique(\"fqid\")\n",
    "        self._cat_col_nunique(\"event_name+name\")\n",
    "        self._cat_col_nunique(\"event_name+room_fqid\")\n",
    "        self._cat_col_nunique(\"event_name+fqid\")\n",
    "\n",
    "        self._agg_features(val_cols=[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"], \n",
    "                           aggs=[\"mean\"])\n",
    "        self._agg_features(val_cols=[\"time_diff\", \"hover_duration\"], \n",
    "                           aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\"])\n",
    "        \n",
    "        self._agg_features(val_cols=[\"elapsed_time\", \"index\"], \n",
    "                           aggs=[\"max\", \"min\"])\n",
    "\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name\")\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"room_fqid\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"fqid\")\n",
    "        self._cat_agg_features(val_cols=[\"elapsed_time\"],\n",
    "                               aggs=[\"max\", \"min\"],\n",
    "                               cat_col=\"fqid\")\n",
    "\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"text_fqid\")\n",
    "        self._cat_agg_features(val_cols=[\"elapsed_time\", \"index\"],\n",
    "                               aggs=[\"max\", \"min\"],\n",
    "                               cat_col=\"text_fqid\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"level\")\n",
    "        self._cat_agg_features(val_cols=[\"elapsed_time\", \"index\"],\n",
    "                               aggs=[\"max\", \"min\"],\n",
    "                               cat_col=\"level\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"],\n",
    "                               aggs=[\"mean\"],\n",
    "                               cat_col=\"event_name\",\n",
    "                               not_use_cats=['checkpoint', 'map_hover', 'object_hover'])        \n",
    "        self._cat_agg_features(val_cols=[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"],\n",
    "                               aggs=[\"mean\"],\n",
    "                               cat_col=\"name\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"hover_duration\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name\",\n",
    "                               not_use_cats=['cutscene_click', 'person_click', 'navigate_click',\n",
    "                                             'observation_click', 'notification_click', 'object_click',\n",
    "                                             'map_click', 'checkpoint', 'notebook_click'])\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+name\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+room_fqid\") \n",
    "\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+fqid\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"hover_duration\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+fqid\")    \n",
    "\n",
    "        \n",
    "        self._cat_change_cnt(\"text_fqid\")\n",
    "        self._cat_change_cnt(\"room_fqid\")\n",
    "\n",
    "        if self.group == \"0-4\":\n",
    "            self._add_minigame_features(\"tunic\", \"tunic.hub.slip\")\n",
    "            self._add_minigame_features(\"plaque\", \"plaque.face.date\")\n",
    "        \n",
    "        elif self.group == \"5-12\":\n",
    "            self._add_minigame_features(\"businesscards\", \"businesscards.card_bingo.bingo\")\n",
    "            self._add_minigame_features(\"logbook\", \"logbook.page.bingo\")\n",
    "            self._add_minigame_features(\"reader\", \"reader.paper2.bingo\")\n",
    "            self._add_minigame_features(\"journals\", \"journals.pic_2.bingo\")\n",
    "        \n",
    "        elif self.group == \"13-22\":\n",
    "            self._add_minigame_features(\"tracks\", \"tracks.hub.deer\")\n",
    "            self._add_minigame_features(\"reader_flag\", \"reader_flag.paper2.bingo\")\n",
    "            self._add_minigame_features(\"journals_flag\", \"journals_flag.pic_0.bingo\")\n",
    "        \n",
    "        self.result = self.result.merge(self.features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesInf:\n",
    "    def __init__(self, sessions_df, labels, feature_select=False, need_create_features=[]):\n",
    "        self.sessions_df = sessions_df.sort_values([\"index\"], ignore_index=True)\n",
    "        self.result = labels\n",
    "        self.group = sessions_df[\"level_group\"].values[0]\n",
    "        self.use_cols = [\n",
    "            \"elapsed_time\", \"event_name\", \"name\", \"level\", \"page\", \"index\",\n",
    "            \"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\",\n",
    "            \"hover_duration\", \"text\", \"fqid\", \"room_fqid\", \"text_fqid\", \"event_name+name\", \"event_name+room_fqid\", \"time_diff\", \"event_name+fqid\"\n",
    "        ]\n",
    "        self.feature_select = feature_select\n",
    "        self.need_create_features = need_create_features\n",
    "\n",
    "\n",
    "    def _prep(self):\n",
    "        self.sessions_df[\"event_name+name\"] = self.sessions_df[\"event_name\"] + \"_\" + self.sessions_df[\"name\"]\n",
    "        self.sessions_df[\"event_name+room_fqid\"] = self.sessions_df[\"event_name\"] + \"_\" + self.sessions_df[\"room_fqid\"]\n",
    "        self.sessions_df[\"event_name+fqid\"] = self.sessions_df[\"event_name\"] + \"_\" + self.sessions_df[\"fqid\"]\n",
    "        self.sessions_df[\"time_diff\"] = self.sessions_df[\"elapsed_time\"] - self.sessions_df[\"elapsed_time\"].shift(1).values\n",
    "        self.sessions_df[\"time_diff\"] = np.where(self.sessions_df[\"time_diff\"]<0, 0, self.sessions_df[\"time_diff\"])\n",
    "        self.sessions_df[\"time_diff\"] = np.nan_to_num(self.sessions_df[\"time_diff\"], 0)\n",
    "        # dataframeの各列をnumpy arrayで保持\n",
    "        self.sessions = {}\n",
    "        for c in self.use_cols:\n",
    "            self.sessions[c] = self.sessions_df[c].values\n",
    "        \n",
    "\n",
    "    def _total_record_cnt(self):\n",
    "        \"\"\"level_groupごとのレコード数\n",
    "        \"\"\"\n",
    "        feat_name = f\"{self.group}_record_cnt\"\n",
    "        if self.feature_select & (feat_name not in self.need_create_features):\n",
    "            pass\n",
    "        else:\n",
    "            add_feature = len(self.sessions[\"elapsed_time\"])\n",
    "            self.result[feat_name] = add_feature\n",
    "\n",
    "    def _group_elapsed_time(self):\n",
    "        \"\"\"level_groupごと、epapsed_timeのmax - min（経過時間）\n",
    "        \"\"\"\n",
    "        feat_name = f\"{self.group}_group_elapsed_time\"\n",
    "        if self.feature_select & (feat_name not in self.need_create_features):\n",
    "            pass\n",
    "        else:\n",
    "            add_feature = np.max(self.sessions[\"elapsed_time\"]) - np.min(self.sessions[\"elapsed_time\"])\n",
    "            self.result[feat_name] = np.float32(add_feature)\n",
    "\n",
    "    def _cat_record_cnt(self, cat_col):\n",
    "        \"\"\"level_groupごと、各{cat}のレコード数\n",
    "        \"\"\"\n",
    "        cat_list = cat_col_lists[self.group][cat_col]\n",
    "        for cat in cat_list:\n",
    "            feat_name = f\"{self.group}_{cat_col}_{str(cat)}_record_cnt\"\n",
    "            if self.feature_select & (feat_name not in self.need_create_features):\n",
    "                pass\n",
    "            else:\n",
    "                add_feature = (self.sessions[cat_col] == cat).astype(int).sum()\n",
    "                self.result[feat_name] = add_feature\n",
    "\n",
    "    def _cat_col_nunique(self, cat_col):\n",
    "        \"\"\"level_groupごと、[col]のユニーク数\n",
    "        \"\"\"\n",
    "        feat_name = f\"{self.group}_{cat_col}_nunique\"\n",
    "        if self.feature_select & (feat_name not in self.need_create_features):\n",
    "            pass\n",
    "        else:\n",
    "            self.result[feat_name] = self.sessions_df[cat_col].dropna().nunique()     \n",
    "\n",
    "    def _agg_features(self, val_cols, aggs):\n",
    "        for val_col, agg in itertools.product(val_cols, aggs):\n",
    "            feat_name = f\"{self.group}_{val_col}_{agg}\"\n",
    "            if self.feature_select & (feat_name not in self.need_create_features):\n",
    "                pass\n",
    "            else:\n",
    "                if agg == \"mean\":\n",
    "                    add_feature = np.nanmean(self.sessions[val_col])\n",
    "                elif agg == \"max\":\n",
    "                    add_feature = np.nanmax(self.sessions[val_col])\n",
    "                elif agg == \"min\":\n",
    "                    add_feature = np.nanmin(self.sessions[val_col])\n",
    "                elif agg == \"std\":\n",
    "                    add_feature = np.nanstd(self.sessions[val_col], ddof=1)\n",
    "                elif agg == \"sum\":\n",
    "                    add_feature = np.nansum(self.sessions[val_col])\n",
    "                elif agg == \"median\":\n",
    "                    add_feature = np.nanmedian(self.sessions[val_col])\n",
    "                self.result[feat_name] = np.float32(add_feature)\n",
    "\n",
    "    def _cat_agg_features(self, val_cols, aggs, cat_col, not_use_cats=None):\n",
    "        if not_use_cats is not None:\n",
    "            cat_list = [c for c in cat_col_lists[self.group][cat_col] if c not in not_use_cats]\n",
    "        else:\n",
    "            cat_list = cat_col_lists[self.group][cat_col]\n",
    "\n",
    "        for cat in cat_list:\n",
    "            idx = self.sessions[cat_col] == cat\n",
    "        \n",
    "            if idx.sum() == 0:\n",
    "                for val_col, agg in itertools.product(val_cols, aggs):\n",
    "                    feat_name = f\"{self.group}_{cat_col}_{cat}_{val_col}_{agg}\"\n",
    "                    if self.feature_select & (feat_name not in self.need_create_features):\n",
    "                        pass\n",
    "                    else:\n",
    "                        self.result[feat_name] = np.float32(-1)\n",
    "            else:\n",
    "                for val_col, agg in itertools.product(val_cols, aggs):\n",
    "                    feat_name = f\"{self.group}_{cat_col}_{cat}_{val_col}_{agg}\"\n",
    "                    if self.feature_select & (feat_name not in self.need_create_features):\n",
    "                        pass\n",
    "                    else:\n",
    "                        tmp = self.sessions[val_col][idx]\n",
    "                        if agg == \"mean\":\n",
    "                            add_feature = np.nanmean(tmp)\n",
    "                        elif agg == \"max\":\n",
    "                            add_feature = np.nanmax(tmp)\n",
    "                        elif agg == \"min\":\n",
    "                            add_feature = np.nanmin(tmp)\n",
    "                        elif agg == \"std\":\n",
    "                            add_feature = np.nanstd(tmp, ddof=1)\n",
    "                        elif agg == \"sum\":\n",
    "                            add_feature = np.nansum(tmp)\n",
    "                        elif agg == \"median\":\n",
    "                            add_feature = np.nanmedian(tmp)\n",
    "                        if np.isnan(add_feature):\n",
    "                            self.result[feat_name] = np.float32(-1)\n",
    "                        else:\n",
    "                            self.result[feat_name] = np.float32(add_feature)\n",
    "\n",
    "    def _cat_change_cnt(self, cat_col):\n",
    "        \"\"\"cat_colの変化回数\n",
    "        \"\"\"\n",
    "        feat_name = f\"{self.group}_{cat_col}_change_cnt\"\n",
    "        if self.feature_select & (feat_name not in self.need_create_features):\n",
    "            pass\n",
    "        else:\n",
    "            tmp = self.sessions_df[cat_col].copy()\n",
    "            tmp = tmp.fillna(\"nan\")\n",
    "            self.result[feat_name] = (tmp != tmp.shift(1)).sum()\n",
    "\n",
    "\n",
    "    def _add_minigame_features(self, start_fqid, end_fqid):\n",
    "        game_name = start_fqid\n",
    "        start_indexes = self.sessions_df[(self.sessions_df[\"event_name\"]==\"navigate_click\")&(self.sessions_df[\"fqid\"]==start_fqid)][\"index\"].values\n",
    "        end_indexes = self.sessions_df[(self.sessions_df[\"event_name\"]==\"object_click\")&(self.sessions_df[\"fqid\"]==end_fqid)][\"index\"].values\n",
    "        if len(start_indexes) > 0:\n",
    "            start_index = start_indexes[0]\n",
    "        else:\n",
    "            start_index = np.nan\n",
    "        if len(end_indexes) > 0:\n",
    "            end_index = end_indexes[0]\n",
    "        else:\n",
    "            end_index = np.nan\n",
    "\n",
    "        if start_index < end_index:\n",
    "            mini_game_sessions = self.sessions_df[(self.sessions_df[\"index\"]>start_index)&(self.sessions_df[\"index\"]<=end_index)].copy()\n",
    "            record_cnt = len(mini_game_sessions)\n",
    "            total_duration = mini_game_sessions[\"time_diff\"].sum()\n",
    "            total_hover_duration = mini_game_sessions[\"hover_duration\"].sum()\n",
    "\n",
    "            hover_sessions = mini_game_sessions[mini_game_sessions[\"event_name\"]==\"object_hover\"].copy()\n",
    "            if len(hover_sessions) > 0:\n",
    "                hover_cnt = len(hover_sessions)\n",
    "            else:\n",
    "                hover_cnt = 0\n",
    "\n",
    "            click_sessions = mini_game_sessions[mini_game_sessions[\"event_name\"]==\"object_click\"].copy()\n",
    "            if len(click_sessions) > 0:\n",
    "                click_cnt = len(click_sessions)\n",
    "            else:\n",
    "                click_cnt = 0\n",
    "                                    \n",
    "        else:\n",
    "            record_cnt = 0\n",
    "            total_duration = 0\n",
    "            total_hover_duration = 0\n",
    "            hover_cnt = 0\n",
    "            click_cnt = 0\n",
    "        \n",
    "        self.result[f\"{self.group}_minigame_{game_name}_record_cnt\"] = record_cnt\n",
    "        self.result[f\"{self.group}_minigame_{game_name}_total_duration\"] = total_duration\n",
    "        self.result[f\"{self.group}_minigame_{game_name}_total_hover_duration\"] = total_hover_duration\n",
    "        self.result[f\"{self.group}_minigame_{game_name}_hover_cnt\"] = hover_cnt\n",
    "        self.result[f\"{self.group}_minigame_{game_name}_click_cnt\"] = click_cnt\n",
    "            \n",
    "\n",
    "    def get_test(self):\n",
    "        self._prep()\n",
    "        self._total_record_cnt()\n",
    "        self._group_elapsed_time()\n",
    "        self._cat_record_cnt(\"event_name\")\n",
    "        self._cat_record_cnt(\"name\")\n",
    "        self._cat_record_cnt(\"page\")\n",
    "        self._cat_record_cnt(\"level\")\n",
    "        self._cat_record_cnt(\"room_fqid\")\n",
    "        self._cat_record_cnt(\"fqid\")\n",
    "        self._cat_record_cnt(\"text_fqid\")\n",
    "        self._cat_record_cnt(\"event_name+name\")\n",
    "        self._cat_record_cnt(\"event_name+room_fqid\")\n",
    "        self._cat_record_cnt(\"event_name+fqid\")\n",
    "        self._cat_col_nunique(\"text\")\n",
    "        self._cat_col_nunique(\"text_fqid\")\n",
    "        self._cat_col_nunique(\"room_fqid\")\n",
    "        self._cat_col_nunique(\"fqid\")\n",
    "        self._cat_col_nunique(\"event_name+name\")\n",
    "        self._cat_col_nunique(\"event_name+room_fqid\")\n",
    "        self._cat_col_nunique(\"event_name+fqid\")\n",
    "\n",
    "        self._agg_features(val_cols=[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"], \n",
    "                           aggs=[\"mean\"])\n",
    "        self._agg_features(val_cols=[\"time_diff\", \"hover_duration\"], \n",
    "                           aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\"])\n",
    "        \n",
    "        self._agg_features(val_cols=[\"elapsed_time\", \"index\"], \n",
    "                           aggs=[\"max\", \"min\"])\n",
    "\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name\")\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"room_fqid\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"fqid\")\n",
    "        self._cat_agg_features(val_cols=[\"elapsed_time\"],\n",
    "                               aggs=[\"max\", \"min\"],\n",
    "                               cat_col=\"fqid\")\n",
    "\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"text_fqid\")\n",
    "        self._cat_agg_features(val_cols=[\"elapsed_time\", \"index\"],\n",
    "                               aggs=[\"max\", \"min\"],\n",
    "                               cat_col=\"text_fqid\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"level\")\n",
    "        self._cat_agg_features(val_cols=[\"elapsed_time\", \"index\"],\n",
    "                               aggs=[\"max\", \"min\"],\n",
    "                               cat_col=\"level\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"],\n",
    "                               aggs=[\"mean\"],\n",
    "                               cat_col=\"event_name\",\n",
    "                               not_use_cats=['checkpoint', 'map_hover', 'object_hover'])        \n",
    "        self._cat_agg_features(val_cols=[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"],\n",
    "                               aggs=[\"mean\"],\n",
    "                               cat_col=\"name\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"hover_duration\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name\",\n",
    "                               not_use_cats=['cutscene_click', 'person_click', 'navigate_click',\n",
    "                                             'observation_click', 'notification_click', 'object_click',\n",
    "                                             'map_click', 'checkpoint', 'notebook_click'])\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+name\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+room_fqid\") \n",
    "\n",
    "        self._cat_agg_features(val_cols=[\"time_diff\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+fqid\")\n",
    "        \n",
    "        self._cat_agg_features(val_cols=[\"hover_duration\"],\n",
    "                               aggs=[\"mean\", \"max\", \"min\", \"std\", \"sum\", \"median\"],\n",
    "                               cat_col=\"event_name+fqid\")   \n",
    "\n",
    "        \n",
    "        self._cat_change_cnt(\"text_fqid\")\n",
    "        self._cat_change_cnt(\"room_fqid\")\n",
    "\n",
    "        if self.group == \"0-4\":\n",
    "            self._add_minigame_features(\"tunic\", \"tunic.hub.slip\")\n",
    "            self._add_minigame_features(\"plaque\", \"plaque.face.date\")\n",
    "        \n",
    "        elif self.group == \"5-12\":\n",
    "            self._add_minigame_features(\"businesscards\", \"businesscards.card_bingo.bingo\")\n",
    "            self._add_minigame_features(\"logbook\", \"logbook.page.bingo\")\n",
    "            self._add_minigame_features(\"reader\", \"reader.paper2.bingo\")\n",
    "            self._add_minigame_features(\"journals\", \"journals.pic_2.bingo\")\n",
    "        \n",
    "        elif self.group == \"13-22\":\n",
    "            self._add_minigame_features(\"tracks\", \"tracks.hub.deer\")\n",
    "            self._add_minigame_features(\"reader_flag\", \"reader_flag.paper2.bingo\")\n",
    "            self._add_minigame_features(\"journals_flag\", \"journals_flag.pic_0.bingo\")\n",
    "        \n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(sessions, labels):\n",
    "    # labelデータの整形\n",
    "    labels = transform_labels_df_train(labels)\n",
    "\n",
    "    # 特徴量生成\n",
    "    feat = FeaturesTrain(sessions, labels)\n",
    "    train = feat.get_train()\n",
    "    #train[\"question\"] = train[\"question\"].astype(\"category\")\n",
    "\n",
    "    return train\n",
    "\n",
    "def get_test_dataset(sessions, labels, feature_select=False, need_create_features=[]):\n",
    "    # labelデータの整形\n",
    "    labels = transform_labels_df_inf(labels)\n",
    "\n",
    "    # 特徴量生成\n",
    "    feat = FeaturesInf(sessions, labels, feature_select, need_create_features)\n",
    "    test = feat.get_test()\n",
    "    #test[\"question\"] = test[\"question\"].astype(\"category\")\n",
    "\n",
    "    return test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(oof):\n",
    "    logloss = log_loss(oof[\"correct\"], oof[\"pred\"])\n",
    "\n",
    "    # find best th\n",
    "    scores = []; thresholds = []\n",
    "    best_score = 0; best_threshold = 0\n",
    "\n",
    "    for threshold in np.arange(0.4,0.81,0.01):\n",
    "        preds = (oof[\"pred\"].values>threshold).astype(int)\n",
    "        m = f1_score(oof[\"correct\"].values, preds, average='macro')   \n",
    "        scores.append(m)\n",
    "        thresholds.append(threshold)\n",
    "        if m>best_score:\n",
    "            best_score = m\n",
    "            best_threshold = threshold\n",
    "    print(\"logloss\", format(logloss, \".6f\"))\n",
    "    print(\"best_score\", format(best_score, \".6f\"))\n",
    "    print(\"best_threshold\", format(best_threshold, \".3f\"))\n",
    "\n",
    "    # Q別スコア\n",
    "    print(\"---\"*10)\n",
    "    for q in range(18):\n",
    "        q = q + 1\n",
    "        preds = (oof[oof[\"question\"]==q][\"pred\"].values>threshold).astype(int)\n",
    "        m = f1_score(oof[oof[\"question\"]==q][\"correct\"].values, preds, average='macro')\n",
    "        print(f\"Q{q} : F1 = {format(m, '.6f')}\")\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesSelect:\n",
    "    def __init__(self, df, init_features, corr_th=0.99):\n",
    "        self.init_features = init_features\n",
    "        self.df = cudf.from_pandas(df)\n",
    "        self.corr_th = corr_th\n",
    "        self.drop_cols = []\n",
    "    \n",
    "    def _high_corr_features_drop(self):\n",
    "        num_cols = self.df[self.init_features].select_dtypes(include=\"number\").columns\n",
    "\n",
    "        # 特徴量間の相関行列を計算\n",
    "        corr_matrix = self.df[num_cols].fillna(-1).corr().abs().to_pandas()\n",
    "        # 相関行列の上三角行列を取得します。（相関行列が対称であるため、重複する相関を取り除くため）\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "        drop_cols = []\n",
    "        for c in num_cols:\n",
    "            if any(upper[c] > self.corr_th):\n",
    "                drop_cols.append(c)\n",
    "                upper = upper.drop(index=c)\n",
    "        print(f\"特徴量間の相関性が高い特徴量を{str(len(drop_cols))}個抽出\")\n",
    "        self.df = self.df.drop(columns=drop_cols)\n",
    "        self.drop_cols = list(set(self.drop_cols + drop_cols))\n",
    "\n",
    "    def features_select(self):\n",
    "        self._high_corr_features_drop()\n",
    "        selected_features = list(set(self.init_features) - set(self.drop_cols))\n",
    "        print(f\"{str(len(self.init_features))} -> {str(len(selected_features))}\")\n",
    "\n",
    "        return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    oofs = []\n",
    "    prev_features_df = None # 次のlevel_groupで特徴量を使うための保持データ。0-4は前のlevel_groupがないので初期値はNone\n",
    "    for group in level_group_list:\n",
    "        print(group)\n",
    "        # データ読み込み\n",
    "        train_sessions = pd.read_csv(cfg.prep_dir + f\"train{group}_cleaned.csv\")\n",
    "        labels = pd.read_csv(cfg.prep_dir + f\"train_labels{group}.csv\")\n",
    "        train = get_train_dataset(train_sessions, labels)\n",
    "\n",
    "        # 一つ前のlevel_groupの特徴量を追加\n",
    "        if prev_features_df is not None:\n",
    "            train = train.merge(prev_features_df, on=[\"session_id\"], how=\"left\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 前のlevel_groupのquestionパートの経過時間特徴量\n",
    "        if group == \"5-12\":\n",
    "            train[\"0-4_question_duration_time\"] = train[\"5-12_elapsed_time_min\"] - train[\"0-4_elapsed_time_max\"]\n",
    "            train[\"0-4_question_duration_index\"] = train[\"5-12_index_min\"] - train[\"0-4_index_max\"]\n",
    "        elif group == \"13-22\":\n",
    "            train[\"5-12_question_duration_time\"] = train[\"13-22_elapsed_time_min\"] - train[\"5-12_elapsed_time_max\"]\n",
    "            train[\"5-12_question_duration_index\"] = train[\"13-22_index_min\"] - train[\"5-12_index_max\"]\n",
    "    \n",
    "        target = \"correct\"\n",
    "        not_use_cols = [target, \"session_id\", \"level_group\"]\n",
    "        features = [c for c in train.columns if c not in not_use_cols]\n",
    "\n",
    "        # 特徴量選択\n",
    "        if cfg.base_exp is None:\n",
    "            features = FeaturesSelect(train, features).features_select()\n",
    "        else:\n",
    "            # 使用する特徴量の抽出\n",
    "            features = pd.read_csv(cfg.output_dir + f\"{cfg.base_exp}/fi_{group}.csv\").head(cfg.n_features)[\"feature\"].tolist()\n",
    "\n",
    "        gkf = GroupKFold(n_splits=cfg.n_splits)\n",
    "        fis = []\n",
    "        \n",
    "        oof_groups = []\n",
    "        for i, (tr_idx, vl_idx) in enumerate(gkf.split(train[features], train[target], train[\"session_id\"])):\n",
    "            model_path = cfg.output_dir + f\"{cfg.exp_name}/{cfg.exp_name}_model_{group}_{i}.xgb\"\n",
    "            \n",
    "            print(f\"fold : {i}\")\n",
    "            tr_x, tr_y = train.iloc[tr_idx][features], train.iloc[tr_idx][target]\n",
    "            vl_x, vl_y = train.iloc[vl_idx][features], train.iloc[vl_idx][target]\n",
    "\n",
    "\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"modelが既に存在するのでロード : {model_path}\")\n",
    "                model = XGBClassifier()\n",
    "                model.load_model(model_path)\n",
    "            else:\n",
    "                model = XGBClassifier(**params)\n",
    "                model.fit(tr_x, tr_y, eval_set=[(vl_x, vl_y)], verbose=100)\n",
    "            # モデル出力\n",
    "            model.save_model(cfg.output_dir + f\"{cfg.exp_name}/{cfg.exp_name}_model_{group}_{i}.xgb\")\n",
    "        \n",
    "            # valid_pred\n",
    "            oof_fold = train.iloc[vl_idx].copy()\n",
    "            oof_fold[\"pred\"] = model.predict_proba(vl_x)[:,1]\n",
    "            oof_groups.append(oof_fold)\n",
    "\n",
    "            # 特徴量重要度\n",
    "            fi_fold = pd.DataFrame()\n",
    "            fi_fold[\"feature\"] = model.feature_names_in_\n",
    "            fi_fold[\"importance\"] = model.feature_importances_\n",
    "            fi_fold[\"fold\"] = i\n",
    "            fis.append(fi_fold)\n",
    "\n",
    "        fi = pd.concat(fis)    \n",
    "        fi = fi.groupby(\"feature\")[\"importance\"].mean().reset_index()\n",
    "        fi = fi.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "        fi.to_csv(cfg.output_dir + f\"{cfg.exp_name}/fi_{group}.csv\", index=False)\n",
    "\n",
    "        oof_group = pd.concat(oof_groups)\n",
    "        oofs.append(oof_group)\n",
    "\n",
    "        # 次のlevel_groupで使う用に特徴量を保持\n",
    "        prev_features_df = train.groupby(\"session_id\").head(1).drop(columns=[\"question\", \"correct\", \"level_group\"])\n",
    "\n",
    "        # meta_featureの付与\n",
    "        meta_df = oof_group.groupby(\"session_id\")[\"pred\"].agg([\"mean\", \"max\", \"min\", \"std\"]).reset_index()\n",
    "        meta_df = meta_df.rename(columns={\"mean\":f\"{group}_pred_mean\", \"max\":f\"{group}_pred_max\", \"min\":f\"{group}_pred_min\", \"std\":f\"{group}_pred_std\"})\n",
    "        prev_features_df = prev_features_df.merge(meta_df, on=\"session_id\", how=\"left\")\n",
    "\n",
    "    # cv\n",
    "    oof = pd.concat(oofs)\n",
    "    best_threshold = calc_metrics(oof)\n",
    "    cfg.best_threshold = best_threshold\n",
    "    oof[[\"session_id\", \"question\", \"pred\", \"correct\"]].to_csv(cfg.output_dir + f\"{cfg.exp_name}/oof.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_iter_train():\n",
    "    \"\"\"trainデータのiter分割を適用したtest_sample\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(cfg.input_dir + \"_old/test.csv\")\n",
    "    sub = pd.read_csv(cfg.input_dir + \"_old/sample_submission.csv\")\n",
    "    sub[\"level_group\"] = sub[\"session_level\"].apply(lambda x: x.split(\"_\")[-1])\n",
    "    \n",
    "    # groupbyでiter作るときにgroup_levelの順番が崩れないように\n",
    "    test[\"level_group2\"] = test[\"level_group\"].str.replace(\"13-22\", \"6\")\n",
    "    sub[\"level_group2\"] = sub[\"level_group\"].str.replace(\"13-22\", \"6\")\n",
    "\n",
    "    tests = [df[1].drop(columns=[\"session_level\", \"level_group2\"]).reset_index(drop=True) for df in test.groupby(\"level_group2\")]\n",
    "    subs = [df[1].drop(columns=[\"session_level\", \"level_group2\"]).reset_index(drop=True) for df in sub.groupby(\"level_group2\")]\n",
    "    return zip(tests, subs)\n",
    "\n",
    "def get_mock_iter_test():\n",
    "    \"\"\"testデータのiter分割を適用したtest_sample\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(cfg.input_dir + \"_old/test.csv\")\n",
    "    sub = pd.read_csv(cfg.input_dir + \"_old/sample_submission.csv\")\n",
    "    \n",
    "    # groupbyでiter作るときにgroup_levelの順番が崩れないように\n",
    "    test[\"session_level\"] = test[\"session_level\"].str.replace(\"13-22\", \"6\")\n",
    "    sub[\"session_level\"] = sub[\"session_level\"].str.replace(\"13-22\", \"6\")\n",
    "\n",
    "    tests = [df[1].drop(columns=\"session_level\").reset_index(drop=True) for df in test.groupby(\"session_level\")]\n",
    "    subs = [df[1].drop(columns=\"session_level\").reset_index(drop=True) for df in sub.groupby(\"session_level\")]\n",
    "    return zip(tests, subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(mode):\n",
    "    if mode == \"local_cv\":\n",
    "        # time series apiを模したiterをモックとして用意する\n",
    "        iter_test = get_mock_iter_test()\n",
    "        start_time = time.time()\n",
    "    elif mode == \"kaggle_inf\":\n",
    "        env = jo_wilder_310.make_env()\n",
    "        iter_test = env.iter_test()\n",
    "        \n",
    "    model_dict = {}\n",
    "    features_dict = {}\n",
    "    for g in level_group_list:\n",
    "        if mode == \"local_cv\":\n",
    "            model_paths = [cfg.output_dir + f\"{cfg.exp_name}/{cfg.exp_name}_model_{g}_{i}.lgb\" for i in range(cfg.n_splits)]\n",
    "        elif mode == \"kaggle_inf\":\n",
    "            model_paths = [f\"/kaggle/input/jo-wilder-{cfg.exp_name}/{cfg.exp_name}_model_{g}_{i}.lgb\" for i in range(cfg.n_splits)]\n",
    "        model_dict[g] = [lgb.Booster(model_file=p) for p in model_paths]\n",
    "        features_dict[g] = model_dict[g][0].feature_name()\n",
    "    need_create_features = features_dict[\"0-4\"] + features_dict[\"5-12\"] + features_dict[\"13-22\"]\n",
    "    not_drop_cols = [\"0-4_elapsed_time_max\", \"0-4_index_max\", \"5-12_elapsed_time_max\", \"5-12_index_max\", \"13-22_elapsed_time_max\", \"13-22_index_max\",\n",
    "                     \"0-4_elapsed_time_min\", \"0-4_index_min\", \"5-12_elapsed_time_min\", \"5-12_index_min\", \"13-22_elapsed_time_min\", \"13-22_index_min\"]\n",
    "    need_create_features = need_create_features + not_drop_cols\n",
    "    need_create_features = list(set(need_create_features))\n",
    "    \n",
    "    prev_features_df = None\n",
    "    for (test_sessions, sample_submission) in iter_test:\n",
    "        level_group = test_sessions[\"level_group\"].values[0]\n",
    "        test = get_test_dataset(test_sessions, sample_submission, feature_select=True, need_create_features=need_create_features)\n",
    "        features = features_dict[level_group]\n",
    "        preds = np.zeros(len(test))\n",
    "\n",
    "        if level_group == \"0-4\":\n",
    "            pass\n",
    "        else:\n",
    "            test = test.merge(prev_features_df, on=[\"session_id\"], how=\"left\")\n",
    "\n",
    "        # 前のlevel_groupのquestionパートの経過時間特徴量\n",
    "        if level_group == \"5-12\":\n",
    "            test[\"0-4_question_duration_time\"] = test[\"5-12_elapsed_time_min\"] - test[\"0-4_elapsed_time_max\"]\n",
    "            test[\"0-4_question_duration_index\"] = test[\"5-12_index_min\"] - test[\"0-4_index_max\"]\n",
    "        elif level_group == \"13-22\":\n",
    "            test[\"5-12_question_duration_time\"] = test[\"13-22_elapsed_time_min\"] - test[\"5-12_elapsed_time_max\"]\n",
    "            test[\"5-12_question_duration_index\"] = test[\"13-22_index_min\"] - test[\"5-12_index_max\"]\n",
    "\n",
    "        prev_features_df = test.groupby(\"session_id\").head(1).drop(columns=[\"question\", \"correct\"])\n",
    "\n",
    "        for i in range(cfg.n_splits):\n",
    "            model = model_dict[level_group][i]\n",
    "            preds += model.predict(test[features], num_iteration=model.best_iteration) / cfg.n_splits\n",
    "        test[\"pred\"] = preds\n",
    "        preds = (preds>cfg.best_threshold).astype(int)\n",
    "        sample_submission[\"correct\"] = preds\n",
    "\n",
    "        # meta_featureの付与\n",
    "        meta_df = test.groupby(\"session_id\")[\"pred\"].agg([\"mean\", \"max\", \"min\", \"std\"]).reset_index()\n",
    "        meta_df = meta_df.rename(columns={\"mean\":f\"{level_group}_pred_mean\", \"max\":f\"{level_group}_pred_max\", \"min\":f\"{level_group}_pred_min\", \"std\":f\"{level_group}_pred_std\"})\n",
    "        prev_features_df = prev_features_df.merge(meta_df, on=\"session_id\", how=\"left\")\n",
    "\n",
    "        if mode == \"local_cv\":\n",
    "            print(sample_submission[\"correct\"].values)\n",
    "        elif mode == \"kaggle_inf\":\n",
    "            env.predict(sample_submission)\n",
    "    if mode == \"local_cv\":\n",
    "        process_time = format(time.time() - start_time, \".1f\")\n",
    "        print(\"sample_inf処理時間 : \", process_time, \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_train_test_process_identity():\n",
    "    iter_train = get_mock_iter_train()\n",
    "    iter_test = get_mock_iter_test()\n",
    "\n",
    "    print(\"train_iter\")\n",
    "    train_df_dict = {}\n",
    "    train_features_dict = {}\n",
    "    prev_features_df = None\n",
    "    for (sessions, sub) in iter_train:\n",
    "        group = sessions[\"level_group\"].values[0]\n",
    "        print(group)\n",
    "        train = get_train_dataset(sessions, sub)\n",
    "        if prev_features_df is not None:\n",
    "            train = train.merge(prev_features_df, on=[\"session_id\"], how=\"left\")\n",
    "        else:\n",
    "            pass\n",
    "            # 前のlevel_groupのquestionパートの経過時間特徴量\n",
    "        if group == \"5-12\":\n",
    "            train[\"0-4_question_duration_time\"] = train[\"5-12_elapsed_time_min\"] - train[\"0-4_elapsed_time_max\"]\n",
    "            train[\"0-4_question_duration_index\"] = train[\"5-12_index_min\"] - train[\"0-4_index_max\"]\n",
    "        elif group == \"13-22\":\n",
    "            train[\"5-12_question_duration_time\"] = train[\"13-22_elapsed_time_min\"] - train[\"5-12_elapsed_time_max\"]\n",
    "            train[\"5-12_question_duration_index\"] = train[\"13-22_index_min\"] - train[\"5-12_index_max\"]\n",
    "        target = \"correct\"\n",
    "        not_use_cols = [target, \"session_id\", \"level_group\"]\n",
    "        features = [c for c in train.columns if c not in not_use_cols]\n",
    "        train_df_dict[group] = train[[\"session_id\"]+features].sort_values([\"session_id\", \"question\"], ignore_index=True)\n",
    "        prev_features_df = train[[\"session_id\"]+features].groupby(\"session_id\").head(1).drop(columns=\"question\")\n",
    "        train_features_dict[group] = features\n",
    "\n",
    "\n",
    "    print(\"test_iter\")\n",
    "    test_dfs_0_4 = []\n",
    "    test_dfs_5_12 = []\n",
    "    test_dfs_13_22 = []\n",
    "    prev_features_df = None\n",
    "    for (test_sessions, sample_submission) in iter_test:\n",
    "        level_group = test_sessions[\"level_group\"].values[0]\n",
    "        session_id = test_sessions[\"session_id\"].values[0]\n",
    "        print(session_id, level_group)\n",
    "        features = train_features_dict[level_group]\n",
    "        test = get_test_dataset(test_sessions, sample_submission)\n",
    "\n",
    "        if level_group == \"0-4\":\n",
    "            pass\n",
    "        else:\n",
    "            test = test.merge(prev_features_df, on=[\"session_id\"], how=\"left\")\n",
    "\n",
    "        # 前のlevel_groupのquestionパートの経過時間特徴量\n",
    "        if level_group == \"5-12\":\n",
    "            test[\"0-4_question_duration_time\"] = test[\"5-12_elapsed_time_min\"] - test[\"0-4_elapsed_time_max\"]\n",
    "            test[\"0-4_question_duration_index\"] = test[\"5-12_index_min\"] - test[\"0-4_index_max\"]\n",
    "        elif level_group == \"13-22\":\n",
    "            test[\"5-12_question_duration_time\"] = test[\"13-22_elapsed_time_min\"] - test[\"5-12_elapsed_time_max\"]\n",
    "            test[\"5-12_question_duration_index\"] = test[\"13-22_index_min\"] - test[\"5-12_index_max\"]\n",
    "        target = \"correct\"\n",
    "        not_use_cols = [target, \"session_id\", \"level_group\"]\n",
    "        features = [c for c in test.columns if c not in not_use_cols]\n",
    "        prev_features_df = test[[\"session_id\"]+features].groupby(\"session_id\").head(1).drop(columns=\"question\")\n",
    "        if level_group == \"0-4\":\n",
    "            test_dfs_0_4.append(test[[\"session_id\"]+features])\n",
    "        elif level_group == \"5-12\":\n",
    "            test_dfs_5_12.append(test[[\"session_id\"]+features])\n",
    "        elif level_group == \"13-22\":\n",
    "            test_dfs_13_22.append(test[[\"session_id\"]+features])\n",
    "        \n",
    "\n",
    "    test_dfs_0_4 = pd.concat(test_dfs_0_4, ignore_index=True).sort_values([\"session_id\", \"question\"], ignore_index=True)\n",
    "    test_dfs_5_12 = pd.concat(test_dfs_5_12, ignore_index=True).sort_values([\"session_id\", \"question\"], ignore_index=True)\n",
    "    test_dfs_13_22 = pd.concat(test_dfs_13_22, ignore_index=True).sort_values([\"session_id\", \"question\"], ignore_index=True)\n",
    "\n",
    "    assert train_df_dict[\"0-4\"][train_features_dict[\"0-4\"]].equals(test_dfs_0_4[train_features_dict[\"0-4\"]])\n",
    "    assert train_df_dict[\"5-12\"][train_features_dict[\"5-12\"]].equals(test_dfs_5_12[train_features_dict[\"5-12\"]])\n",
    "    assert train_df_dict[\"13-22\"][train_features_dict[\"13-22\"]].equals(test_dfs_13_22[train_features_dict[\"13-22\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iter\n",
      "0-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 340.93it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 363.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 339.24it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 288.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 334.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 362.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 343.98it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 323.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 367.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_iter\n",
      "20090109393214576 0-4\n",
      "20090109393214576 5-12\n",
      "20090109393214576 13-22\n",
      "20090312143683264 0-4\n",
      "20090312143683264 5-12\n",
      "20090312143683264 13-22\n",
      "20090312331414616 0-4\n",
      "20090312331414616 5-12\n",
      "20090312331414616 13-22\n",
      "0-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23562/23562 [01:48<00:00, 217.59it/s]\n",
      "100%|██████████| 23562/23562 [01:47<00:00, 219.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量間の相関性が高い特徴量を1144個抽出\n",
      "2377 -> 1233\n",
      "fold : 0\n",
      "[0]\tvalidation_0-logloss:0.68145\n",
      "[100]\tvalidation_0-logloss:0.32383\n",
      "[200]\tvalidation_0-logloss:0.28591\n",
      "[300]\tvalidation_0-logloss:0.27543\n",
      "[400]\tvalidation_0-logloss:0.27198\n",
      "[500]\tvalidation_0-logloss:0.27064\n",
      "[600]\tvalidation_0-logloss:0.26995\n",
      "[700]\tvalidation_0-logloss:0.26964\n",
      "[800]\tvalidation_0-logloss:0.26931\n",
      "[900]\tvalidation_0-logloss:0.26927\n",
      "[1000]\tvalidation_0-logloss:0.26929\n",
      "[1100]\tvalidation_0-logloss:0.26932\n",
      "[1175]\tvalidation_0-logloss:0.26929\n",
      "fold : 1\n",
      "[0]\tvalidation_0-logloss:0.68132\n",
      "[100]\tvalidation_0-logloss:0.31547\n",
      "[200]\tvalidation_0-logloss:0.27669\n",
      "[300]\tvalidation_0-logloss:0.26663\n",
      "[400]\tvalidation_0-logloss:0.26349\n",
      "[500]\tvalidation_0-logloss:0.26216\n",
      "[600]\tvalidation_0-logloss:0.26151\n",
      "[700]\tvalidation_0-logloss:0.26119\n",
      "[800]\tvalidation_0-logloss:0.26098\n",
      "[900]\tvalidation_0-logloss:0.26086\n",
      "[1000]\tvalidation_0-logloss:0.26081\n",
      "[1100]\tvalidation_0-logloss:0.26070\n",
      "[1200]\tvalidation_0-logloss:0.26068\n",
      "[1300]\tvalidation_0-logloss:0.26073\n",
      "[1376]\tvalidation_0-logloss:0.26072\n",
      "fold : 2\n",
      "[0]\tvalidation_0-logloss:0.68134\n",
      "[100]\tvalidation_0-logloss:0.31718\n",
      "[200]\tvalidation_0-logloss:0.27770\n",
      "[300]\tvalidation_0-logloss:0.26664\n",
      "[400]\tvalidation_0-logloss:0.26332\n",
      "[500]\tvalidation_0-logloss:0.26180\n",
      "[600]\tvalidation_0-logloss:0.26115\n",
      "[700]\tvalidation_0-logloss:0.26067\n",
      "[800]\tvalidation_0-logloss:0.26042\n",
      "[900]\tvalidation_0-logloss:0.26024\n",
      "[1000]\tvalidation_0-logloss:0.26025\n",
      "[1100]\tvalidation_0-logloss:0.26024\n",
      "[1200]\tvalidation_0-logloss:0.26026\n",
      "[1300]\tvalidation_0-logloss:0.26017\n",
      "[1400]\tvalidation_0-logloss:0.26031\n",
      "[1500]\tvalidation_0-logloss:0.26027\n",
      "[1526]\tvalidation_0-logloss:0.26026\n",
      "fold : 3\n",
      "[0]\tvalidation_0-logloss:0.68136\n",
      "[100]\tvalidation_0-logloss:0.31999\n",
      "[200]\tvalidation_0-logloss:0.28252\n",
      "[300]\tvalidation_0-logloss:0.27289\n",
      "[400]\tvalidation_0-logloss:0.26994\n",
      "[500]\tvalidation_0-logloss:0.26885\n",
      "[600]\tvalidation_0-logloss:0.26847\n",
      "[700]\tvalidation_0-logloss:0.26821\n",
      "[800]\tvalidation_0-logloss:0.26805\n",
      "[900]\tvalidation_0-logloss:0.26788\n",
      "[1000]\tvalidation_0-logloss:0.26785\n",
      "[1100]\tvalidation_0-logloss:0.26783\n",
      "[1200]\tvalidation_0-logloss:0.26784\n",
      "[1300]\tvalidation_0-logloss:0.26798\n",
      "[1366]\tvalidation_0-logloss:0.26794\n",
      "fold : 4\n",
      "[0]\tvalidation_0-logloss:0.68148\n",
      "[100]\tvalidation_0-logloss:0.32088\n",
      "[200]\tvalidation_0-logloss:0.28135\n",
      "[300]\tvalidation_0-logloss:0.26989\n",
      "[400]\tvalidation_0-logloss:0.26594\n",
      "[500]\tvalidation_0-logloss:0.26436\n",
      "[600]\tvalidation_0-logloss:0.26348\n",
      "[700]\tvalidation_0-logloss:0.26299\n",
      "[800]\tvalidation_0-logloss:0.26260\n",
      "[900]\tvalidation_0-logloss:0.26242\n",
      "[1000]\tvalidation_0-logloss:0.26241\n",
      "[1100]\tvalidation_0-logloss:0.26245\n",
      "[1200]\tvalidation_0-logloss:0.26241\n",
      "[1203]\tvalidation_0-logloss:0.26242\n",
      "5-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23562/23562 [02:57<00:00, 132.39it/s]\n",
      "100%|██████████| 23562/23562 [03:00<00:00, 130.88it/s]\n",
      "100%|██████████| 23562/23562 [03:00<00:00, 130.29it/s]\n",
      "100%|██████████| 23562/23562 [03:00<00:00, 130.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量間の相関性が高い特徴量を2821個抽出\n",
      "6421 -> 3600\n",
      "fold : 0\n",
      "[0]\tvalidation_0-logloss:0.69049\n",
      "[100]\tvalidation_0-logloss:0.57885\n",
      "[200]\tvalidation_0-logloss:0.55627\n",
      "[300]\tvalidation_0-logloss:0.54624\n",
      "[400]\tvalidation_0-logloss:0.54092\n",
      "[500]\tvalidation_0-logloss:0.53781\n",
      "[600]\tvalidation_0-logloss:0.53639\n",
      "[700]\tvalidation_0-logloss:0.53553\n",
      "[800]\tvalidation_0-logloss:0.53497\n",
      "[900]\tvalidation_0-logloss:0.53455\n",
      "[1000]\tvalidation_0-logloss:0.53409\n",
      "[1100]\tvalidation_0-logloss:0.53381\n",
      "[1200]\tvalidation_0-logloss:0.53354\n",
      "[1300]\tvalidation_0-logloss:0.53329\n",
      "[1400]\tvalidation_0-logloss:0.53307\n",
      "[1500]\tvalidation_0-logloss:0.53289\n",
      "[1600]\tvalidation_0-logloss:0.53273\n",
      "[1700]\tvalidation_0-logloss:0.53260\n",
      "[1800]\tvalidation_0-logloss:0.53252\n",
      "[1900]\tvalidation_0-logloss:0.53242\n",
      "[2000]\tvalidation_0-logloss:0.53225\n",
      "[2100]\tvalidation_0-logloss:0.53211\n",
      "[2200]\tvalidation_0-logloss:0.53202\n",
      "[2300]\tvalidation_0-logloss:0.53196\n",
      "[2400]\tvalidation_0-logloss:0.53192\n",
      "[2500]\tvalidation_0-logloss:0.53187\n",
      "[2600]\tvalidation_0-logloss:0.53180\n",
      "[2700]\tvalidation_0-logloss:0.53180\n",
      "[2800]\tvalidation_0-logloss:0.53175\n",
      "[2900]\tvalidation_0-logloss:0.53167\n",
      "[3000]\tvalidation_0-logloss:0.53170\n",
      "[3100]\tvalidation_0-logloss:0.53167\n",
      "[3200]\tvalidation_0-logloss:0.53162\n",
      "[3300]\tvalidation_0-logloss:0.53163\n",
      "[3400]\tvalidation_0-logloss:0.53161\n",
      "[3500]\tvalidation_0-logloss:0.53160\n",
      "[3600]\tvalidation_0-logloss:0.53153\n",
      "[3700]\tvalidation_0-logloss:0.53151\n",
      "[3800]\tvalidation_0-logloss:0.53152\n",
      "[3900]\tvalidation_0-logloss:0.53148\n",
      "[4000]\tvalidation_0-logloss:0.53141\n",
      "[4100]\tvalidation_0-logloss:0.53137\n",
      "[4200]\tvalidation_0-logloss:0.53136\n",
      "[4300]\tvalidation_0-logloss:0.53142\n",
      "[4377]\tvalidation_0-logloss:0.53144\n",
      "fold : 1\n",
      "[0]\tvalidation_0-logloss:0.69043\n",
      "[100]\tvalidation_0-logloss:0.57866\n",
      "[200]\tvalidation_0-logloss:0.55637\n",
      "[300]\tvalidation_0-logloss:0.54731\n",
      "[400]\tvalidation_0-logloss:0.54239\n",
      "[500]\tvalidation_0-logloss:0.53970\n",
      "[600]\tvalidation_0-logloss:0.53836\n",
      "[700]\tvalidation_0-logloss:0.53745\n",
      "[800]\tvalidation_0-logloss:0.53691\n",
      "[900]\tvalidation_0-logloss:0.53643\n",
      "[1000]\tvalidation_0-logloss:0.53612\n",
      "[1100]\tvalidation_0-logloss:0.53577\n",
      "[1200]\tvalidation_0-logloss:0.53551\n",
      "[1300]\tvalidation_0-logloss:0.53533\n",
      "[1400]\tvalidation_0-logloss:0.53531\n",
      "[1500]\tvalidation_0-logloss:0.53514\n",
      "[1600]\tvalidation_0-logloss:0.53504\n",
      "[1700]\tvalidation_0-logloss:0.53492\n",
      "[1800]\tvalidation_0-logloss:0.53482\n",
      "[1900]\tvalidation_0-logloss:0.53479\n",
      "[2000]\tvalidation_0-logloss:0.53470\n",
      "[2100]\tvalidation_0-logloss:0.53467\n",
      "[2200]\tvalidation_0-logloss:0.53466\n",
      "[2300]\tvalidation_0-logloss:0.53469\n",
      "[2374]\tvalidation_0-logloss:0.53469\n",
      "fold : 2\n",
      "[0]\tvalidation_0-logloss:0.69037\n",
      "[100]\tvalidation_0-logloss:0.57707\n",
      "[200]\tvalidation_0-logloss:0.55497\n",
      "[300]\tvalidation_0-logloss:0.54563\n",
      "[400]\tvalidation_0-logloss:0.54074\n",
      "[500]\tvalidation_0-logloss:0.53782\n",
      "[600]\tvalidation_0-logloss:0.53659\n",
      "[700]\tvalidation_0-logloss:0.53585\n",
      "[800]\tvalidation_0-logloss:0.53534\n",
      "[900]\tvalidation_0-logloss:0.53502\n",
      "[1000]\tvalidation_0-logloss:0.53470\n",
      "[1100]\tvalidation_0-logloss:0.53442\n",
      "[1200]\tvalidation_0-logloss:0.53429\n",
      "[1300]\tvalidation_0-logloss:0.53412\n",
      "[1400]\tvalidation_0-logloss:0.53406\n",
      "[1500]\tvalidation_0-logloss:0.53394\n",
      "[1600]\tvalidation_0-logloss:0.53384\n",
      "[1700]\tvalidation_0-logloss:0.53368\n",
      "[1800]\tvalidation_0-logloss:0.53357\n",
      "[1900]\tvalidation_0-logloss:0.53351\n",
      "[2000]\tvalidation_0-logloss:0.53345\n",
      "[2100]\tvalidation_0-logloss:0.53335\n",
      "[2200]\tvalidation_0-logloss:0.53323\n",
      "[2300]\tvalidation_0-logloss:0.53319\n",
      "[2400]\tvalidation_0-logloss:0.53320\n",
      "[2500]\tvalidation_0-logloss:0.53313\n",
      "[2600]\tvalidation_0-logloss:0.53308\n",
      "[2700]\tvalidation_0-logloss:0.53302\n",
      "[2800]\tvalidation_0-logloss:0.53305\n",
      "[2900]\tvalidation_0-logloss:0.53302\n",
      "[3000]\tvalidation_0-logloss:0.53298\n",
      "[3100]\tvalidation_0-logloss:0.53293\n",
      "[3200]\tvalidation_0-logloss:0.53293\n",
      "[3300]\tvalidation_0-logloss:0.53295\n",
      "[3400]\tvalidation_0-logloss:0.53293\n",
      "[3500]\tvalidation_0-logloss:0.53293\n",
      "[3600]\tvalidation_0-logloss:0.53286\n",
      "[3700]\tvalidation_0-logloss:0.53289\n",
      "[3800]\tvalidation_0-logloss:0.53287\n",
      "[3900]\tvalidation_0-logloss:0.53280\n",
      "[4000]\tvalidation_0-logloss:0.53278\n",
      "[4100]\tvalidation_0-logloss:0.53284\n",
      "[4196]\tvalidation_0-logloss:0.53280\n",
      "fold : 3\n",
      "[0]\tvalidation_0-logloss:0.69049\n",
      "[100]\tvalidation_0-logloss:0.57904\n",
      "[200]\tvalidation_0-logloss:0.55611\n",
      "[300]\tvalidation_0-logloss:0.54622\n",
      "[400]\tvalidation_0-logloss:0.54111\n",
      "[500]\tvalidation_0-logloss:0.53794\n",
      "[600]\tvalidation_0-logloss:0.53655\n",
      "[700]\tvalidation_0-logloss:0.53579\n",
      "[800]\tvalidation_0-logloss:0.53517\n",
      "[900]\tvalidation_0-logloss:0.53490\n",
      "[1000]\tvalidation_0-logloss:0.53456\n",
      "[1100]\tvalidation_0-logloss:0.53418\n",
      "[1200]\tvalidation_0-logloss:0.53394\n",
      "[1300]\tvalidation_0-logloss:0.53374\n",
      "[1400]\tvalidation_0-logloss:0.53355\n",
      "[1500]\tvalidation_0-logloss:0.53339\n",
      "[1600]\tvalidation_0-logloss:0.53335\n",
      "[1700]\tvalidation_0-logloss:0.53320\n",
      "[1800]\tvalidation_0-logloss:0.53309\n",
      "[1900]\tvalidation_0-logloss:0.53305\n",
      "[2000]\tvalidation_0-logloss:0.53301\n",
      "[2100]\tvalidation_0-logloss:0.53296\n",
      "[2200]\tvalidation_0-logloss:0.53294\n",
      "[2300]\tvalidation_0-logloss:0.53292\n",
      "[2400]\tvalidation_0-logloss:0.53289\n",
      "[2500]\tvalidation_0-logloss:0.53283\n",
      "[2600]\tvalidation_0-logloss:0.53280\n",
      "[2700]\tvalidation_0-logloss:0.53281\n",
      "[2800]\tvalidation_0-logloss:0.53272\n",
      "[2900]\tvalidation_0-logloss:0.53270\n",
      "[3000]\tvalidation_0-logloss:0.53268\n",
      "[3100]\tvalidation_0-logloss:0.53266\n",
      "[3200]\tvalidation_0-logloss:0.53261\n",
      "[3300]\tvalidation_0-logloss:0.53260\n",
      "[3400]\tvalidation_0-logloss:0.53260\n",
      "[3477]\tvalidation_0-logloss:0.53263\n",
      "fold : 4\n",
      "[0]\tvalidation_0-logloss:0.69048\n",
      "[100]\tvalidation_0-logloss:0.58027\n",
      "[200]\tvalidation_0-logloss:0.55772\n",
      "[300]\tvalidation_0-logloss:0.54790\n",
      "[400]\tvalidation_0-logloss:0.54252\n",
      "[500]\tvalidation_0-logloss:0.53913\n",
      "[600]\tvalidation_0-logloss:0.53768\n",
      "[700]\tvalidation_0-logloss:0.53688\n",
      "[800]\tvalidation_0-logloss:0.53634\n",
      "[900]\tvalidation_0-logloss:0.53588\n",
      "[1000]\tvalidation_0-logloss:0.53554\n",
      "[1100]\tvalidation_0-logloss:0.53522\n",
      "[1200]\tvalidation_0-logloss:0.53491\n",
      "[1300]\tvalidation_0-logloss:0.53469\n",
      "[1400]\tvalidation_0-logloss:0.53461\n",
      "[1500]\tvalidation_0-logloss:0.53437\n",
      "[1600]\tvalidation_0-logloss:0.53415\n",
      "[1700]\tvalidation_0-logloss:0.53408\n",
      "[1800]\tvalidation_0-logloss:0.53398\n",
      "[1900]\tvalidation_0-logloss:0.53389\n",
      "[2000]\tvalidation_0-logloss:0.53383\n",
      "[2100]\tvalidation_0-logloss:0.53377\n",
      "[2200]\tvalidation_0-logloss:0.53369\n",
      "[2300]\tvalidation_0-logloss:0.53365\n",
      "[2400]\tvalidation_0-logloss:0.53361\n",
      "[2500]\tvalidation_0-logloss:0.53361\n",
      "[2600]\tvalidation_0-logloss:0.53359\n",
      "[2700]\tvalidation_0-logloss:0.53352\n",
      "[2800]\tvalidation_0-logloss:0.53347\n",
      "[2900]\tvalidation_0-logloss:0.53344\n",
      "[3000]\tvalidation_0-logloss:0.53329\n",
      "[3100]\tvalidation_0-logloss:0.53326\n",
      "[3200]\tvalidation_0-logloss:0.53324\n",
      "[3300]\tvalidation_0-logloss:0.53318\n",
      "[3400]\tvalidation_0-logloss:0.53320\n",
      "[3486]\tvalidation_0-logloss:0.53325\n",
      "13-22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23562/23562 [04:09<00:00, 94.39it/s] \n",
      "100%|██████████| 23562/23562 [04:07<00:00, 95.23it/s] \n",
      "100%|██████████| 23562/23562 [04:03<00:00, 96.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量間の相関性が高い特徴量を4925個抽出\n",
      "11887 -> 6962\n",
      "fold : 0\n",
      "[0]\tvalidation_0-logloss:0.68900\n",
      "[100]\tvalidation_0-logloss:0.53746\n",
      "[200]\tvalidation_0-logloss:0.51763\n",
      "[300]\tvalidation_0-logloss:0.51030\n",
      "[400]\tvalidation_0-logloss:0.50772\n",
      "[500]\tvalidation_0-logloss:0.50681\n",
      "[600]\tvalidation_0-logloss:0.50646\n",
      "[700]\tvalidation_0-logloss:0.50615\n",
      "[800]\tvalidation_0-logloss:0.50612\n",
      "[900]\tvalidation_0-logloss:0.50602\n",
      "[1000]\tvalidation_0-logloss:0.50603\n",
      "[1100]\tvalidation_0-logloss:0.50598\n",
      "[1200]\tvalidation_0-logloss:0.50584\n",
      "[1300]\tvalidation_0-logloss:0.50573\n",
      "[1400]\tvalidation_0-logloss:0.50576\n",
      "[1500]\tvalidation_0-logloss:0.50567\n",
      "[1600]\tvalidation_0-logloss:0.50561\n",
      "[1700]\tvalidation_0-logloss:0.50551\n",
      "[1800]\tvalidation_0-logloss:0.50553\n",
      "[1900]\tvalidation_0-logloss:0.50548\n",
      "[2000]\tvalidation_0-logloss:0.50549\n",
      "[2100]\tvalidation_0-logloss:0.50556\n",
      "[2200]\tvalidation_0-logloss:0.50558\n",
      "[2237]\tvalidation_0-logloss:0.50559\n",
      "fold : 1\n",
      "[0]\tvalidation_0-logloss:0.68904\n",
      "[100]\tvalidation_0-logloss:0.52898\n",
      "[200]\tvalidation_0-logloss:0.50815\n",
      "[300]\tvalidation_0-logloss:0.50091\n",
      "[400]\tvalidation_0-logloss:0.49858\n",
      "[500]\tvalidation_0-logloss:0.49772\n",
      "[600]\tvalidation_0-logloss:0.49733\n",
      "[700]\tvalidation_0-logloss:0.49685\n",
      "[800]\tvalidation_0-logloss:0.49676\n",
      "[900]\tvalidation_0-logloss:0.49673\n",
      "[1000]\tvalidation_0-logloss:0.49667\n",
      "[1100]\tvalidation_0-logloss:0.49657\n",
      "[1200]\tvalidation_0-logloss:0.49639\n",
      "[1300]\tvalidation_0-logloss:0.49640\n",
      "[1400]\tvalidation_0-logloss:0.49647\n",
      "[1409]\tvalidation_0-logloss:0.49646\n",
      "fold : 2\n",
      "[0]\tvalidation_0-logloss:0.68883\n",
      "[100]\tvalidation_0-logloss:0.52976\n",
      "[200]\tvalidation_0-logloss:0.50899\n",
      "[300]\tvalidation_0-logloss:0.50158\n",
      "[400]\tvalidation_0-logloss:0.49920\n",
      "[500]\tvalidation_0-logloss:0.49834\n",
      "[600]\tvalidation_0-logloss:0.49808\n",
      "[700]\tvalidation_0-logloss:0.49782\n",
      "[800]\tvalidation_0-logloss:0.49764\n",
      "[900]\tvalidation_0-logloss:0.49763\n",
      "[1000]\tvalidation_0-logloss:0.49755\n",
      "[1100]\tvalidation_0-logloss:0.49752\n",
      "[1200]\tvalidation_0-logloss:0.49742\n",
      "[1300]\tvalidation_0-logloss:0.49747\n",
      "[1400]\tvalidation_0-logloss:0.49740\n",
      "[1500]\tvalidation_0-logloss:0.49734\n",
      "[1600]\tvalidation_0-logloss:0.49740\n",
      "[1688]\tvalidation_0-logloss:0.49741\n",
      "fold : 3\n",
      "[0]\tvalidation_0-logloss:0.68903\n",
      "[100]\tvalidation_0-logloss:0.53607\n",
      "[200]\tvalidation_0-logloss:0.51601\n",
      "[300]\tvalidation_0-logloss:0.50862\n",
      "[400]\tvalidation_0-logloss:0.50601\n",
      "[500]\tvalidation_0-logloss:0.50525\n",
      "[600]\tvalidation_0-logloss:0.50500\n",
      "[700]\tvalidation_0-logloss:0.50478\n",
      "[800]\tvalidation_0-logloss:0.50466\n",
      "[900]\tvalidation_0-logloss:0.50451\n",
      "[1000]\tvalidation_0-logloss:0.50451\n",
      "[1100]\tvalidation_0-logloss:0.50437\n",
      "[1200]\tvalidation_0-logloss:0.50432\n",
      "[1300]\tvalidation_0-logloss:0.50437\n",
      "[1372]\tvalidation_0-logloss:0.50434\n",
      "fold : 4\n",
      "[0]\tvalidation_0-logloss:0.68901\n",
      "[100]\tvalidation_0-logloss:0.53677\n",
      "[200]\tvalidation_0-logloss:0.51685\n",
      "[300]\tvalidation_0-logloss:0.50919\n",
      "[400]\tvalidation_0-logloss:0.50639\n",
      "[500]\tvalidation_0-logloss:0.50527\n",
      "[600]\tvalidation_0-logloss:0.50479\n",
      "[700]\tvalidation_0-logloss:0.50456\n",
      "[800]\tvalidation_0-logloss:0.50446\n",
      "[900]\tvalidation_0-logloss:0.50418\n",
      "[1000]\tvalidation_0-logloss:0.50404\n",
      "[1100]\tvalidation_0-logloss:0.50388\n",
      "[1200]\tvalidation_0-logloss:0.50384\n",
      "[1300]\tvalidation_0-logloss:0.50389\n",
      "[1392]\tvalidation_0-logloss:0.50385\n",
      "logloss 0.479350\n",
      "best_score 0.697637\n",
      "best_threshold 0.620\n",
      "------------------------------\n",
      "Q1 : F1 = 0.622277\n",
      "Q2 : F1 = 0.547573\n",
      "Q3 : F1 = 0.590172\n",
      "Q4 : F1 = 0.658523\n",
      "Q5 : F1 = 0.421400\n",
      "Q6 : F1 = 0.609913\n",
      "Q7 : F1 = 0.564211\n",
      "Q8 : F1 = 0.387494\n",
      "Q9 : F1 = 0.542500\n",
      "Q10 : F1 = 0.354139\n",
      "Q11 : F1 = 0.410842\n",
      "Q12 : F1 = 0.590509\n",
      "Q13 : F1 = 0.425942\n",
      "Q14 : F1 = 0.522076\n",
      "Q15 : F1 = 0.350901\n",
      "Q16 : F1 = 0.393033\n",
      "Q17 : F1 = 0.371969\n",
      "Q18 : F1 = 0.557036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Could not open /mnt/predict-student-performance-from-game-play/output/exp080/exp080_model_0-4_0.lgb\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Could not open /mnt/predict-student-performance-from-game-play/output/exp080/exp080_model_0-4_0.lgb",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     valid_train_test_process_identity()\n\u001b[1;32m      3\u001b[0m     run_train()\n\u001b[0;32m----> 4\u001b[0m inference(cfg\u001b[39m.\u001b[39;49mmode)\n",
      "Cell \u001b[0;32mIn[49], line 17\u001b[0m, in \u001b[0;36minference\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkaggle_inf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     16\u001b[0m         model_paths \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/kaggle/input/jo-wilder-\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mexp_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mexp_name\u001b[39m}\u001b[39;00m\u001b[39m_model_\u001b[39m\u001b[39m{\u001b[39;00mg\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.lgb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cfg\u001b[39m.\u001b[39mn_splits)]\n\u001b[0;32m---> 17\u001b[0m     model_dict[g] \u001b[39m=\u001b[39m [lgb\u001b[39m.\u001b[39mBooster(model_file\u001b[39m=\u001b[39mp) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model_paths]\n\u001b[1;32m     18\u001b[0m     features_dict[g] \u001b[39m=\u001b[39m model_dict[g][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfeature_name()\n\u001b[1;32m     19\u001b[0m need_create_features \u001b[39m=\u001b[39m features_dict[\u001b[39m\"\u001b[39m\u001b[39m0-4\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m features_dict[\u001b[39m\"\u001b[39m\u001b[39m5-12\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m features_dict[\u001b[39m\"\u001b[39m\u001b[39m13-22\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[49], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkaggle_inf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     16\u001b[0m         model_paths \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/kaggle/input/jo-wilder-\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mexp_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcfg\u001b[39m.\u001b[39mexp_name\u001b[39m}\u001b[39;00m\u001b[39m_model_\u001b[39m\u001b[39m{\u001b[39;00mg\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.lgb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cfg\u001b[39m.\u001b[39mn_splits)]\n\u001b[0;32m---> 17\u001b[0m     model_dict[g] \u001b[39m=\u001b[39m [lgb\u001b[39m.\u001b[39;49mBooster(model_file\u001b[39m=\u001b[39;49mp) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model_paths]\n\u001b[1;32m     18\u001b[0m     features_dict[g] \u001b[39m=\u001b[39m model_dict[g][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfeature_name()\n\u001b[1;32m     19\u001b[0m need_create_features \u001b[39m=\u001b[39m features_dict[\u001b[39m\"\u001b[39m\u001b[39m0-4\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m features_dict[\u001b[39m\"\u001b[39m\u001b[39m5-12\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m features_dict[\u001b[39m\"\u001b[39m\u001b[39m13-22\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:2639\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2637\u001b[0m out_num_iterations \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int(\u001b[39m0\u001b[39m)\n\u001b[1;32m   2638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_void_p()\n\u001b[0;32m-> 2639\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterCreateFromModelfile(\n\u001b[1;32m   2640\u001b[0m     c_str(\u001b[39mstr\u001b[39;49m(model_file)),\n\u001b[1;32m   2641\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_iterations),\n\u001b[1;32m   2642\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle)))\n\u001b[1;32m   2643\u001b[0m out_num_class \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int(\u001b[39m0\u001b[39m)\n\u001b[1;32m   2644\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39mLGBM_BoosterGetNumClasses(\n\u001b[1;32m   2645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m   2646\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(out_num_class)))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Could not open /mnt/predict-student-performance-from-game-play/output/exp080/exp080_model_0-4_0.lgb"
     ]
    }
   ],
   "source": [
    "if cfg.mode == \"local_cv\":\n",
    "    valid_train_test_process_identity()\n",
    "    run_train()\n",
    "inference(cfg.mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
