{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp048"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_fqidごとのtime_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import pathlib\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Cfg:\n",
    "    mode = \"local_cv\" # \"local_cv\" or \"kaggle_inf\" \n",
    "    exp_name = \"exp048\"\n",
    "    input_dir = \"/mnt/predict-student-performance-from-game-play/input/\"\n",
    "    output_dir = \"/mnt/predict-student-performance-from-game-play/output/\"\n",
    "    prep_dir = \"/mnt/predict-student-performance-from-game-play/prep/\"\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    best_threshold = 0.630 # local_cvの結果を入れる\n",
    "cfg = Cfg()\n",
    "\n",
    "if cfg.mode == \"local_cv\":\n",
    "    os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(cfg.output_dir, cfg.exp_name, \"cache\"), exist_ok=True)\n",
    "\n",
    "elif cfg.mode == \"kaggle_inf\":\n",
    "    import jo_wilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary', \n",
    "    'boosting': 'gbdt', \n",
    "    'learning_rate': 0.01, \n",
    "    'metric': 'binary_logloss', \n",
    "    'seed': cfg.seed, \n",
    "    'feature_pre_filter': False, \n",
    "    'lambda_l1': 4.134488140102331, \n",
    "    'lambda_l2': 0.007775200046481757, \n",
    "    'num_leaves': 75, \n",
    "    'feature_fraction': 0.5, \n",
    "    'bagging_fraction': 0.7036110805680353, \n",
    "    'bagging_freq': 3, \n",
    "    'min_data_in_leaf': 50, \n",
    "    'min_child_samples': 100\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used_total = [\n",
    "    'record_cnt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_group_list = ['0-4', '5-12', '13-22']\n",
    "\n",
    "event_name_list = [\n",
    "    'cutscene_click', 'person_click', 'navigate_click',\n",
    "    'observation_click', 'notification_click', 'object_click',\n",
    "    'object_hover', 'map_hover', 'map_click', 'checkpoint',\n",
    "    'notebook_click'\n",
    "]\n",
    "\n",
    "name_list = [\n",
    "    'basic', 'undefined', 'close', 'open', 'prev', 'next'\n",
    "]\n",
    "\n",
    "page_list = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]  \n",
    "\n",
    "level_list = [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "               17, 18, 19, 20, 21, 22]\n",
    "\n",
    "room_fqid_list = ['tunic.historicalsociety.closet',\n",
    " 'tunic.historicalsociety.basement',\n",
    " 'tunic.historicalsociety.entry',\n",
    " 'tunic.historicalsociety.collection',\n",
    " 'tunic.historicalsociety.stacks',\n",
    " 'tunic.kohlcenter.halloffame',\n",
    " 'tunic.capitol_0.hall',\n",
    " 'tunic.historicalsociety.closet_dirty',\n",
    " 'tunic.historicalsociety.frontdesk',\n",
    " 'tunic.humanecology.frontdesk',\n",
    " 'tunic.drycleaner.frontdesk',\n",
    " 'tunic.library.frontdesk',\n",
    " 'tunic.library.microfiche',\n",
    " 'tunic.capitol_1.hall',\n",
    " 'tunic.historicalsociety.cage',\n",
    " 'tunic.historicalsociety.collection_flag',\n",
    " 'tunic.wildlife.center',\n",
    " 'tunic.flaghouse.entry',\n",
    " 'tunic.capitol_2.hall']\n",
    "\n",
    "fqid_list = [\n",
    " 'intro',\n",
    " 'gramps',\n",
    " 'teddy',\n",
    " 'photo',\n",
    " 'notebook',\n",
    " 'retirement_letter',\n",
    " 'tobasement',\n",
    " 'janitor',\n",
    " 'toentry',\n",
    " 'groupconvo',\n",
    " 'report',\n",
    " 'boss',\n",
    " 'wells',\n",
    " 'directory',\n",
    " 'tocollection',\n",
    " 'cs',\n",
    " 'tunic',\n",
    " 'tunic.hub.slip',\n",
    " 'tostacks',\n",
    " 'outtolunch',\n",
    " 'tocloset',\n",
    " 'tomap',\n",
    " 'tunic.historicalsociety',\n",
    " 'tunic.kohlcenter',\n",
    " 'plaque',\n",
    " 'plaque.face.date',\n",
    " 'togrampa',\n",
    " 'tunic.capitol_0',\n",
    " 'chap1_finale',\n",
    " 'chap1_finale_c',\n",
    " 'tocloset_dirty',\n",
    " 'what_happened',\n",
    " 'trigger_scarf',\n",
    " 'trigger_coffee',\n",
    " 'tunic.capitol_1',\n",
    " 'tofrontdesk',\n",
    " 'archivist',\n",
    " 'magnify',\n",
    " 'tunic.humanecology',\n",
    " 'worker',\n",
    " 'businesscards',\n",
    " 'businesscards.card_0.next',\n",
    " 'businesscards.card_1.next',\n",
    " 'businesscards.card_bingo.next',\n",
    " 'businesscards.card_bingo.bingo',\n",
    " 'tohallway',\n",
    " 'tunic.drycleaner',\n",
    " 'logbook',\n",
    " 'logbook.page.bingo',\n",
    " 'tunic.library',\n",
    " 'tomicrofiche',\n",
    " 'reader',\n",
    " 'reader.paper0.next',\n",
    " 'reader.paper1.next',\n",
    " 'reader.paper2.bingo',\n",
    " 'wellsbadge',\n",
    " 'journals',\n",
    " 'journals.hub.topics',\n",
    " 'journals.pic_0.next',\n",
    " 'journals.pic_1.next',\n",
    " 'journals.pic_2.bingo',\n",
    " 'chap2_finale_c',\n",
    " 'ch3start',\n",
    " 'seescratches',\n",
    " 'tocage',\n",
    " 'glasses',\n",
    " 'directory.closeup.archivist',\n",
    " 'key',\n",
    " 'unlockdoor',\n",
    " 'confrontation',\n",
    " 'savedteddy',\n",
    " 'tocollectionflag',\n",
    " 'groupconvo_flag',\n",
    " 'tunic.capitol_2',\n",
    " 'tunic.wildlife',\n",
    " 'coffee',\n",
    " 'crane_ranger',\n",
    " 'remove_cup',\n",
    " 'expert',\n",
    " 'tracks',\n",
    " 'tracks.hub.deer',\n",
    " 'tunic.flaghouse',\n",
    " 'flag_girl',\n",
    " 'colorbook',\n",
    " 'reader_flag',\n",
    " 'reader_flag.paper0.next',\n",
    " 'reader_flag.paper1.next',\n",
    " 'reader_flag.paper2.bingo',\n",
    " 'archivist_glasses',\n",
    " 'journals_flag',\n",
    " 'journals_flag.hub.topics_old',\n",
    " 'journals_flag.hub.topics',\n",
    " 'journals_flag.pic_0.bingo',\n",
    " 'journals_flag.pic_0.next',\n",
    " 'chap4_finale_c',\n",
    " 'block_tocollection',\n",
    " 'reader.paper2.next',\n",
    " 'journals.pic_2.next',\n",
    " 'lockeddoor',\n",
    " 'reader.paper2.prev',\n",
    " 'reader.paper0.prev',\n",
    " 'reader_flag.paper1.prev',\n",
    " 'journals_flag.pic_0_old.next',\n",
    " 'journals_flag.pic_1_old.next',\n",
    " 'door_block_clean',\n",
    " 'door_block_talk',\n",
    " 'block',\n",
    " 'reader_flag.paper2.next',\n",
    " 'journals_flag.pic_1.bingo',\n",
    " 'journals_flag.pic_1.next',\n",
    " 'journals_flag.pic_2.bingo',\n",
    " 'journals_flag.pic_2.next',\n",
    " 'reader_flag.paper0.prev',\n",
    " 'reader.paper1.prev',\n",
    " 'block_magnify',\n",
    " 'journals_flag.pic_2_old.next',\n",
    " 'block_0',\n",
    " 'doorblock',\n",
    " 'block_tomap1',\n",
    " 'block_tomap2',\n",
    " 'reader_flag.paper2.prev',\n",
    " 'need_glasses',\n",
    " 'block_badge',\n",
    " 'block_nelson',\n",
    " 'block_badge_2',\n",
    " 'block_1',\n",
    " 'fox'\n",
    "]\n",
    "\n",
    "text_fqid_list = ['tunic.historicalsociety.closet.intro',\n",
    " 'tunic.historicalsociety.closet.gramps.intro_0_cs_0',\n",
    " 'tunic.historicalsociety.closet.teddy.intro_0_cs_0',\n",
    " 'tunic.historicalsociety.closet.teddy.intro_0_cs_5',\n",
    " 'tunic.historicalsociety.closet.photo',\n",
    " 'tunic.historicalsociety.closet.notebook',\n",
    " 'tunic.historicalsociety.closet.retirement_letter.hub',\n",
    " 'tunic.historicalsociety.basement.janitor',\n",
    " 'tunic.historicalsociety.entry.groupconvo',\n",
    " 'tunic.historicalsociety.entry.boss.talktogramps',\n",
    " 'tunic.historicalsociety.entry.wells.talktogramps',\n",
    " 'tunic.historicalsociety.collection.cs',\n",
    " 'tunic.historicalsociety.collection.tunic.slip',\n",
    " 'tunic.historicalsociety.collection.gramps.found',\n",
    " 'tunic.historicalsociety.stacks.outtolunch',\n",
    " 'tunic.kohlcenter.halloffame.plaque.face.date',\n",
    " 'tunic.kohlcenter.halloffame.togrampa',\n",
    " 'tunic.capitol_0.hall.boss.talktogramps',\n",
    " 'tunic.historicalsociety.closet_dirty.what_happened',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.helpclean',\n",
    " 'tunic.historicalsociety.closet_dirty.trigger_scarf',\n",
    " 'tunic.historicalsociety.closet_dirty.trigger_coffee',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.news',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.hello',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.need_glass_0',\n",
    " 'tunic.historicalsociety.frontdesk.magnify',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.have_glass',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.have_glass_recap',\n",
    " 'tunic.humanecology.frontdesk.worker.intro',\n",
    " 'tunic.humanecology.frontdesk.businesscards.card_bingo.bingo',\n",
    " 'tunic.humanecology.frontdesk.worker.badger',\n",
    " 'tunic.drycleaner.frontdesk.worker.hub',\n",
    " 'tunic.drycleaner.frontdesk.logbook.page.bingo',\n",
    " 'tunic.drycleaner.frontdesk.worker.done',\n",
    " 'tunic.library.frontdesk.worker.hello',\n",
    " 'tunic.library.microfiche.reader.paper2.bingo',\n",
    " 'tunic.library.frontdesk.wellsbadge.hub',\n",
    " 'tunic.library.frontdesk.worker.wells',\n",
    " 'tunic.capitol_1.hall.boss.haveyougotit',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.newspaper',\n",
    " 'tunic.historicalsociety.stacks.journals.pic_2.bingo',\n",
    " 'tunic.historicalsociety.basement.ch3start',\n",
    " 'tunic.historicalsociety.basement.gramps.whatdo',\n",
    " 'tunic.historicalsociety.basement.seescratches',\n",
    " 'tunic.historicalsociety.cage.glasses.beforeteddy',\n",
    " 'tunic.historicalsociety.cage.teddy.trapped',\n",
    " 'tunic.historicalsociety.cage.glasses.afterteddy',\n",
    " 'tunic.historicalsociety.entry.directory.closeup.archivist',\n",
    " 'tunic.historicalsociety.frontdesk.key',\n",
    " 'tunic.historicalsociety.cage.unlockdoor',\n",
    " 'tunic.historicalsociety.cage.confrontation',\n",
    " 'tunic.historicalsociety.basement.savedteddy',\n",
    " 'tunic.historicalsociety.collection_flag.gramps.flag',\n",
    " 'tunic.historicalsociety.entry.groupconvo_flag',\n",
    " 'tunic.historicalsociety.entry.wells.flag',\n",
    " 'tunic.historicalsociety.entry.boss.flag',\n",
    " 'tunic.historicalsociety.entry.wells.flag_recap',\n",
    " 'tunic.historicalsociety.entry.boss.flag_recap',\n",
    " 'tunic.wildlife.center.coffee',\n",
    " 'tunic.wildlife.center.wells.animals',\n",
    " 'tunic.wildlife.center.wells.animals2',\n",
    " 'tunic.wildlife.center.crane_ranger.crane',\n",
    " 'tunic.wildlife.center.remove_cup',\n",
    " 'tunic.wildlife.center.expert.removed_cup',\n",
    " 'tunic.wildlife.center.tracks.hub.deer',\n",
    " 'tunic.wildlife.center.expert.recap',\n",
    " 'tunic.wildlife.center.wells.nodeer',\n",
    " 'tunic.flaghouse.entry.flag_girl.hello',\n",
    " 'tunic.flaghouse.entry.colorbook',\n",
    " 'tunic.flaghouse.entry.flag_girl.symbol',\n",
    " 'tunic.flaghouse.entry.flag_girl.symbol_recap',\n",
    " 'tunic.library.frontdesk.worker.flag',\n",
    " 'tunic.library.microfiche.reader_flag.paper2.bingo',\n",
    " 'tunic.library.frontdesk.worker.nelson',\n",
    " 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation',\n",
    " 'tunic.historicalsociety.stacks.journals_flag.pic_0.bingo',\n",
    " 'tunic.historicalsociety.entry.block_tocollection',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.archivist',\n",
    " 'tunic.historicalsociety.cage.lockeddoor',\n",
    " 'tunic.capitol_2.hall.boss.haveyougotit',\n",
    " 'tunic.drycleaner.frontdesk.worker.done2',\n",
    " 'tunic.library.frontdesk.worker.preflag',\n",
    " 'tunic.historicalsociety.closet_dirty.photo',\n",
    " 'tunic.historicalsociety.collection_flag.gramps.recap',\n",
    " 'tunic.wildlife.center.wells.nodeer_recap',\n",
    " 'tunic.library.frontdesk.worker.flag_recap',\n",
    " 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap',\n",
    " 'tunic.historicalsociety.closet_dirty.door_block_clean',\n",
    " 'tunic.historicalsociety.closet_dirty.door_block_talk',\n",
    " 'tunic.historicalsociety.stacks.block',\n",
    " 'tunic.flaghouse.entry.flag_girl.hello_recap',\n",
    " 'tunic.historicalsociety.stacks.journals_flag.pic_1.bingo',\n",
    " 'tunic.historicalsociety.stacks.journals_flag.pic_2.bingo',\n",
    " 'tunic.historicalsociety.collection.tunic',\n",
    " 'tunic.library.frontdesk.worker.wells_recap',\n",
    " 'tunic.historicalsociety.frontdesk.block_magnify',\n",
    " 'tunic.humanecology.frontdesk.block_0',\n",
    " 'tunic.historicalsociety.basement.gramps.seeyalater',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.need_glass_1',\n",
    " 'tunic.historicalsociety.closet.doorblock',\n",
    " 'tunic.library.frontdesk.worker.droppedbadge',\n",
    " 'tunic.library.frontdesk.worker.hello_short',\n",
    " 'tunic.capitol_1.hall.boss.writeitup',\n",
    " 'tunic.historicalsociety.entry.block_tomap1',\n",
    " 'tunic.historicalsociety.entry.block_tomap2',\n",
    " 'tunic.capitol_0.hall.chap1_finale_c',\n",
    " 'tunic.historicalsociety.collection.gramps.lost',\n",
    " 'tunic.historicalsociety.closet_dirty.gramps.nothing',\n",
    " 'tunic.drycleaner.frontdesk.worker.takealook',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.foundtheodora',\n",
    " 'tunic.historicalsociety.cage.need_glasses',\n",
    " 'tunic.library.frontdesk.worker.nelson_recap',\n",
    " 'tunic.library.frontdesk.block_badge',\n",
    " 'tunic.historicalsociety.frontdesk.archivist.newspaper_recap',\n",
    " 'tunic.kohlcenter.halloffame.block_0',\n",
    " 'tunic.library.frontdesk.block_nelson',\n",
    " 'tunic.capitol_1.hall.chap2_finale_c',\n",
    " 'tunic.library.microfiche.block_0',\n",
    " 'tunic.library.frontdesk.block_badge_2',\n",
    " 'tunic.capitol_2.hall.chap4_finale_c',\n",
    " 'tunic.historicalsociety.collection.gramps.look_0',\n",
    " 'tunic.humanecology.frontdesk.block_1',\n",
    " 'tunic.drycleaner.frontdesk.block_0',\n",
    " 'tunic.wildlife.center.fox.concern',\n",
    " 'tunic.historicalsociety.entry.gramps.hub',\n",
    " 'tunic.drycleaner.frontdesk.block_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels_df(labels_):\n",
    "    \"\"\"\n",
    "    labelsデータを整形する\n",
    "    \"\"\"\n",
    "    labels = labels_.copy()\n",
    "    labels[\"question\"] = labels[\"session_id\"].apply(lambda x: x.split(\"_\")[1].replace(\"q\", \"\")).astype(int)\n",
    "    labels[\"session_id\"] = labels[\"session_id\"].apply(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "    \n",
    "    # trainの特徴量と結合するためにquestionに対応するlabel_groupを列として設けておく\n",
    "    labels[\"level_group\"] = \"\"\n",
    "    labels.loc[labels[\"question\"]<=3, \"level_group\"] = \"0-4\"\n",
    "    labels.loc[(labels[\"question\"]>=4)&(labels[\"question\"]<=13), \"level_group\"] = \"5-12\"\n",
    "    labels.loc[labels[\"question\"]>=14, \"level_group\"] = \"13-22\"\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self, _sessions):\n",
    "        self.sessions = _sessions.copy()\n",
    "        self.features = self.sessions[[\"session_id\", \"level_group\"]].drop_duplicates().copy()\n",
    "\n",
    "    def _prep(self):\n",
    "        self.sessions = self.sessions.sort_values([\"session_id\", \"level_group\", \"elapsed_time\"], ignore_index=True)\n",
    "        self.sessions[\"elapsed_time_diff\"] = self.sessions[\"elapsed_time\"] - self.sessions.groupby([\"session_id\", \"level_group\"])[\"elapsed_time\"].shift(1)\n",
    "\n",
    "    def _record_cnt(self):\n",
    "        \"\"\"level_groupごとのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"record_cnt\"})\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _event_name_record_cnt(self):\n",
    "        \"\"\"level_groupごと、各event_nameのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"event_name\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for event in event_name_list:\n",
    "            new_col = f\"{event}_record_cnt\"\n",
    "            tmp = add_features[add_features[\"event_name\"]==event][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _name_record_cnt(self):\n",
    "        \"\"\"level_groupごと、各nameのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"name\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for name in name_list:\n",
    "            new_col = f\"{name}_record_cnt\"\n",
    "            tmp = add_features[add_features[\"name\"]==name][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _page_record_cnt(self):\n",
    "        \"\"\"level_groupごと、各pageのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"page\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for page in page_list:\n",
    "            new_col = f\"page{str(int(page))}_cnt\"\n",
    "            tmp = add_features[add_features[\"page\"]==page][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _room_fqid_record_cnt(self):\n",
    "        \"\"\"level_groupごと、各room_fqidのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"room_fqid\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for room in room_fqid_list:\n",
    "            new_col = f\"{room}_cnt\"\n",
    "            tmp = add_features[add_features[\"room_fqid\"]==room][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _fqid_record_cnt(self):\n",
    "        \"\"\"level_groupごと、各fqidのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"fqid\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for fqid in fqid_list:\n",
    "            new_col = f\"{fqid}_cnt\"\n",
    "            tmp = add_features[add_features[\"fqid\"]==fqid][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _text_fqid_record_cnt(self):\n",
    "        \"\"\"level_groupごと、各text_fqidのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"text_fqid\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for text_fqid in text_fqid_list:\n",
    "            new_col = f\"{text_fqid}_cnt\"\n",
    "            tmp = add_features[add_features[\"text_fqid\"]==text_fqid][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _level_record_cnt(self):\n",
    "        \"\"\"各levelのレコード数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"level\"])[\"index\"].count().reset_index().rename(columns={\"index\":\"cnt\"})\n",
    "        for level in level_list:\n",
    "            new_col = f\"level{str(int(level))}_cnt\"\n",
    "            tmp = add_features[add_features[\"level\"]==level][[\"session_id\", \"level_group\", \"cnt\"]].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns={\"cnt\": new_col})\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_col] = self.features[new_col].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_col] = -1\n",
    "\n",
    "    def _elapsed_time(self):\n",
    "        \"\"\"level_groupごと、epapsed_timeのmax - min（経過時間）\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\"])[\"elapsed_time\"].agg([max,min]).reset_index()\n",
    "        add_features[\"elapsed_time\"] = add_features[\"max\"] - add_features[\"min\"]\n",
    "        add_features = add_features[[\"session_id\", \"level_group\", \"elapsed_time\"]].copy()\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _coor_mean(self):\n",
    "        \"\"\"level_groupごと、座標系の平均値\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\"])[[\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"]].mean().reset_index()\n",
    "        add_features = add_features.rename(columns={\"room_coor_x\":\"room_coor_x_mean\", \"room_coor_y\":\"room_coor_y_mean\", \"screen_coor_x\":\"screen_coor_x_mean\", \"screen_coor_y\":\"screen_coor_y_mean\"})\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _event_name_coor_mean(self):\n",
    "        \"\"\"level_groupごと、evemt_nameごとの座標系の平均値\n",
    "        \"\"\"\n",
    "        coor_cols = [\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"]\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"event_name\"])[coor_cols].mean().reset_index()\n",
    "        for event in event_name_list:\n",
    "            if event in ['checkpoint', 'map_hover', 'object_hover']:\n",
    "                # これらのデータには座標データが存在しないので特徴量化をスキップ\n",
    "                continue\n",
    "            col_map = {col:f\"{event}_elapsed_{col}_mean\" for col in coor_cols}\n",
    "            new_cols = list(col_map.values())\n",
    "            tmp = add_features[add_features[\"event_name\"]==event].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns=col_map)\n",
    "                tmp = tmp.drop(columns=[\"event_name\"])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "\n",
    "    def _name_coor_mean(self):\n",
    "        \"\"\"level_groupごと、nameごとの座標系の平均値\n",
    "        \"\"\"\n",
    "        coor_cols = [\"room_coor_x\", \"room_coor_y\", \"screen_coor_x\", \"screen_coor_y\"]\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"name\"])[coor_cols].mean().reset_index()\n",
    "        for name in name_list:\n",
    "            col_map = {col:f\"{name}_elapsed_{col}_mean\" for col in coor_cols}\n",
    "            new_cols = list(col_map.values())\n",
    "            tmp = add_features[add_features[\"name\"]==name].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns=col_map)\n",
    "                tmp = tmp.drop(columns=[\"name\"])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "\n",
    "    def _cat_col_nunique(self, col):\n",
    "        \"\"\"level_groupごと、[col]のユニーク数\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.dropna(subset=[col]).drop_duplicates([\"session_id\", \"level_group\", col])\n",
    "        add_features = add_features.groupby([\"session_id\", \"level_group\"])[\"index\"].count().reset_index().rename(columns={\"index\":f\"{col}_nunique\"})\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _elapsed_time_diff_agg(self):\n",
    "        \"\"\"level_groupごと、前後のレコードのelapsed_timeの差分に関する集計量\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.copy()\n",
    "        add_features = add_features.groupby([\"session_id\", \"level_group\"])[\"elapsed_time_diff\"].agg([\"max\", \"min\", \"mean\", \"std\"]).reset_index()\n",
    "        add_features = add_features.rename(columns={\"max\":\"elapsed_time_diff_max\", \"min\":\"elapsed_time_diff_min\", \"mean\":\"elapsed_time_diff_mean\", \"std\":\"elapsed_time_diff_std\"})\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "    def _event_name_elapsed_time_diff_agg(self, agg):\n",
    "        \"\"\"level_group、event_nameごとelapsed_timeの差分に関する集計量\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"event_name\"])[\"elapsed_time_diff\"].agg(agg).reset_index()\n",
    "        for event in event_name_list:\n",
    "            col_map = {a:f\"{event}_elapsed_time_diff_{a}\" for a in agg}\n",
    "            new_cols = list(col_map.values())\n",
    "            tmp = add_features[add_features[\"event_name\"]==event].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns=col_map)\n",
    "                tmp = tmp.drop(columns=[\"event_name\"])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "\n",
    "    def _room_fqid_elapsed_time_diff_agg(self, agg):\n",
    "        \"\"\"level_group、room_fqidごとelapsed_timeの差分に関する集計量\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"room_fqid\"])[\"elapsed_time_diff\"].agg(agg).reset_index()\n",
    "        for room in room_fqid_list:\n",
    "            col_map = {a:f\"{room}_elapsed_time_diff_{a}\" for a in agg}\n",
    "            new_cols = list(col_map.values())\n",
    "            tmp = add_features[add_features[\"room_fqid\"]==room].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns=col_map)\n",
    "                tmp = tmp.drop(columns=[\"room_fqid\"])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "\n",
    "    def _fqid_elapsed_time_diff_agg(self, agg):\n",
    "        \"\"\"level_group、fqidごとelapsed_timeの差分に関する集計量\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"fqid\"])[\"elapsed_time_diff\"].agg(agg).reset_index()\n",
    "        for fqid in fqid_list:\n",
    "            col_map = {a:f\"{fqid}_elapsed_time_diff_{a}\" for a in agg}\n",
    "            new_cols = list(col_map.values())\n",
    "            tmp = add_features[add_features[\"fqid\"]==fqid].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns=col_map)\n",
    "                tmp = tmp.drop(columns=[\"fqid\"])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "\n",
    "    def _text_fqid_elapsed_time_diff_agg(self, agg):\n",
    "        \"\"\"level_group、text_fqidごとelapsed_timeの差分に関する集計量\n",
    "        \"\"\"\n",
    "        add_features = self.sessions.groupby([\"session_id\", \"level_group\", \"text_fqid\"])[\"elapsed_time_diff\"].agg(agg).reset_index()\n",
    "        for text_fqid in text_fqid_list:\n",
    "            col_map = {a:f\"{text_fqid}_elapsed_time_diff_{a}\" for a in agg}\n",
    "            new_cols = list(col_map.values())\n",
    "            tmp = add_features[add_features[\"text_fqid\"]==text_fqid].copy()\n",
    "            if len(tmp) > 0:\n",
    "                tmp = tmp.rename(columns=col_map)\n",
    "                tmp = tmp.drop(columns=[\"text_fqid\"])\n",
    "                self.features = self.features.merge(tmp, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "                self.features[new_cols] = self.features[new_cols].fillna(-1)\n",
    "            else:\n",
    "                self.features[new_cols] = -1\n",
    "                \n",
    "    def _hover_duration_agg(self, agg):\n",
    "        \"\"\"level_groupごと、前後のレコードのelapsed_timeの差分に関する集計量\n",
    "        \"\"\"\n",
    "        col_map = {a:f\"hover_duration_{a}\" for a in agg}\n",
    "        add_features = self.sessions.copy()\n",
    "        add_features = add_features.groupby([\"session_id\", \"level_group\"])[\"hover_duration\"].agg(agg).reset_index()\n",
    "        add_features = add_features.rename(columns=col_map)\n",
    "        self.features = self.features.merge(add_features, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "\n",
    "\n",
    "    def get_features(self):\n",
    "        self._prep()\n",
    "        self._record_cnt()\n",
    "        self._event_name_record_cnt()\n",
    "        self._name_record_cnt()\n",
    "        self._elapsed_time()\n",
    "        self._coor_mean()\n",
    "        self._cat_col_nunique(\"text\")\n",
    "        self._elapsed_time_diff_agg()\n",
    "        self._event_name_elapsed_time_diff_agg([\"mean\", \"max\", \"min\", \"std\"])\n",
    "        self._event_name_coor_mean()\n",
    "        self._name_coor_mean()\n",
    "        self._page_record_cnt()\n",
    "        self._hover_duration_agg([\"mean\", \"max\", \"min\", \"std\"])\n",
    "        self._level_record_cnt()\n",
    "        self._room_fqid_elapsed_time_diff_agg([\"mean\", \"max\", \"min\", \"std\"])\n",
    "        self._room_fqid_record_cnt()\n",
    "        self._fqid_record_cnt()\n",
    "        self._fqid_elapsed_time_diff_agg([\"mean\", \"max\", \"min\", \"std\"])\n",
    "        self._text_fqid_record_cnt()\n",
    "        self._text_fqid_elapsed_time_diff_agg([\"mean\", \"max\", \"min\", \"std\"])\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class History:\n",
    "    def __init__(self):\n",
    "        self.store = {}\n",
    "        for c in features_used_total:\n",
    "            self.store[c] = defaultdict(int)\n",
    "\n",
    "    def record(self, train):\n",
    "        df = train.drop_duplicates(\"session_id\").set_index(\"session_id\")[features_used_total]\n",
    "        for session in df.index:\n",
    "            for c in features_used_total:\n",
    "                self.store[c][session] += df.at[session, c]\n",
    "\n",
    "    def add_total_features(self, train):\n",
    "        for c in features_used_total:\n",
    "            train[f\"total_{c}\"] = train[\"session_id\"].map(self.store[c])\n",
    "        return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(oof):\n",
    "    logloss = log_loss(oof[\"correct\"], oof[\"pred\"])\n",
    "\n",
    "    # find best th\n",
    "    scores = []; thresholds = []\n",
    "    best_score = 0; best_threshold = 0\n",
    "\n",
    "    for threshold in np.arange(0.4,0.81,0.01):\n",
    "        preds = (oof[\"pred\"].values>threshold).astype(int)\n",
    "        m = f1_score(oof[\"correct\"].values, preds, average='macro')   \n",
    "        scores.append(m)\n",
    "        thresholds.append(threshold)\n",
    "        if m>best_score:\n",
    "            best_score = m\n",
    "            best_threshold = threshold\n",
    "    print(\"logloss\", format(logloss, \".6f\"))\n",
    "    print(\"best_score\", format(best_score, \".6f\"))\n",
    "    print(\"best_threshold\", format(best_threshold, \".3f\"))\n",
    "\n",
    "    # Q別スコア\n",
    "    print(\"---\"*10)\n",
    "    for q in range(18):\n",
    "        q = q + 1\n",
    "        preds = (oof[oof[\"question\"]==q][\"pred\"].values>threshold).astype(int)\n",
    "        m = f1_score(oof[oof[\"question\"]==q][\"correct\"].values, preds, average='macro')\n",
    "        print(f\"Q{q} : F1 = {format(m, '.6f')}\")\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(sessions, labels, hist):\n",
    "    # labelデータの整形\n",
    "    labels = transform_labels_df(labels)\n",
    "\n",
    "    # 特徴量生成\n",
    "    feat = Features(sessions)\n",
    "    features = feat.get_features()\n",
    "    \n",
    "    train = features.merge(labels, on=[\"session_id\", \"level_group\"], how=\"left\")\n",
    "    train[\"level_group\"] = train[\"level_group\"].map({\"0-4\":0, \"5-12\":1, \"13-22\":2}).astype(\"category\")\n",
    "    train[\"question\"] = train[\"question\"].astype(\"category\")\n",
    "\n",
    "    # level_groupの特徴量記録＆過去のgroup含めたtotal値の特徴量取得\n",
    "    hist.record(train)\n",
    "    train = hist.add_total_features(train)\n",
    "\n",
    "    return train, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    dfs = []\n",
    "    hist = History()\n",
    "    for group in level_group_list:\n",
    "        # データ読み込み\n",
    "        train_sessions = pd.read_csv(cfg.prep_dir + f\"train{group}.csv\")\n",
    "        labels = pd.read_csv(cfg.prep_dir + f\"train_labels{group}.csv\")\n",
    "        train_group, hist = get_train_data(train_sessions, labels, hist)\n",
    "        dfs.append(train_group)\n",
    "    train = pd.concat(dfs, ignore_index=True)\n",
    "    # concatするとcategory型がリセットされてしまうので再度cast\n",
    "    train[\"level_group\"] = train[\"level_group\"].astype(\"category\")\n",
    "    train[\"question\"] = train[\"question\"].astype(\"category\")\n",
    "\n",
    "    target = \"correct\"\n",
    "    not_use_cols = [target, \"session_id\", \"level_group\"]\n",
    "    features = [c for c in train.columns if c not in not_use_cols]\n",
    "\n",
    "    gkf = GroupKFold(n_splits=cfg.n_splits)\n",
    "    fis = []\n",
    "    oofs = []\n",
    "    for i, (tr_idx, vl_idx) in enumerate(gkf.split(train[features], train[target], train[\"session_id\"])):\n",
    "        print(f\"fold : {i}\")\n",
    "        tr_x, tr_y = train.iloc[tr_idx][features], train.iloc[tr_idx][target]\n",
    "        vl_x, vl_y = train.iloc[vl_idx][features], train.iloc[vl_idx][target]\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)\n",
    "\n",
    "        model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n",
    "                        num_boost_round=2000000, early_stopping_rounds=100, verbose_eval=100)\n",
    "        # モデル出力\n",
    "        model.save_model(cfg.output_dir + f\"{cfg.exp_name}/{cfg.exp_name}_model{i}.lgb\")\n",
    "        \n",
    "        # valid_pred\n",
    "        oof_fold = train.iloc[vl_idx].copy()\n",
    "        oof_fold[\"pred\"] = model.predict(vl_x, num_iteration=model.best_iteration)\n",
    "        oofs.append(oof_fold)\n",
    "\n",
    "        # 特徴量重要度\n",
    "        fi_fold = pd.DataFrame()\n",
    "        fi_fold[\"feature\"] = model.feature_name()\n",
    "        fi_fold[\"importance\"] = model.feature_importance(importance_type=\"gain\")\n",
    "        fi_fold[\"fold\"] = i\n",
    "        fis.append(fi_fold)\n",
    "\n",
    "    fi = pd.concat(fis)    \n",
    "    fi_n = fi['feature'].nunique()\n",
    "    order = list(fi.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\n",
    "    plt.figure(figsize=(10, fi_n*0.2))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=fi, order=order)\n",
    "    plt.title(f\"LGBM importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(cfg.output_dir + f'{cfg.exp_name}/lgbm_importance.png')\n",
    "\n",
    "    # cv\n",
    "    oof = pd.concat(oofs)\n",
    "    best_threshold = calc_metrics(oof)\n",
    "    cfg.best_threshold = best_threshold\n",
    "    oof.to_csv(cfg.output_dir + f\"{cfg.exp_name}/oof.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_iter_test():\n",
    "    test = pd.read_csv(cfg.input_dir + \"test.csv\")\n",
    "    sub = pd.read_csv(cfg.input_dir + \"sample_submission.csv\")\n",
    "    tests = [df[1].drop(columns=\"session_level\").reset_index(drop=True) for df in test.groupby(\"session_level\")]\n",
    "    subs = [df[1].drop(columns=\"session_level\").reset_index(drop=True) for df in sub.groupby(\"session_level\")]\n",
    "    return zip(subs, tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(mode):\n",
    "    if mode == \"local_cv\":\n",
    "        # time series apiを模したiterをモックとして用意する\n",
    "        iter_test = get_mock_iter_test()\n",
    "        start_time = time.time()\n",
    "    elif mode == \"kaggle_inf\":\n",
    "        env = jo_wilder.make_env()\n",
    "        iter_test = env.iter_test()\n",
    "        \n",
    "    models = []\n",
    "    for i in range(cfg.n_splits):\n",
    "        if mode == \"local_cv\":\n",
    "            model_path = cfg.output_dir + f\"{cfg.exp_name}/{cfg.exp_name}_model{i}.lgb\"\n",
    "        elif mode == \"kaggle_inf\":\n",
    "            model_path = f\"/kaggle/input/jo-wilder-{cfg.exp_name}/{cfg.exp_name}_model{i}.lgb\"\n",
    "        models.append(lgb.Booster(model_file=model_path))\n",
    "    \n",
    "    hist = History()\n",
    "    for (sample_submission, test_sessions) in iter_test:\n",
    "        test, hist = get_train_data(test_sessions, sample_submission, hist)\n",
    "        preds = np.zeros(len(test))\n",
    "        for i in range(cfg.n_splits):\n",
    "            model = models[i]\n",
    "            features = model.feature_name()\n",
    "            preds += model.predict(test[features], num_iteration=model.best_iteration) / cfg.n_splits\n",
    "        preds = (preds>cfg.best_threshold).astype(int)\n",
    "        sample_submission[\"correct\"] = preds\n",
    "\n",
    "        if mode == \"local_cv\":\n",
    "            print(sample_submission[\"correct\"].values)\n",
    "        elif mode == \"kaggle_inf\":\n",
    "            env.predict(sample_submission)\n",
    "    if mode == \"local_cv\":\n",
    "        process_time = format(time.time() - start_time, \".1f\")\n",
    "        print(\"sample_inf処理時間 : \", process_time, \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "[1 0 1 1 1]\n",
      "[1 0 1 1 0 1 0 0 1 0]\n",
      "[0 1 1]\n",
      "[0 0 1 0 1]\n",
      "[0 0 0 0 0 0 0 0 1 0]\n",
      "[1 1 1]\n",
      "[1 0 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 0]\n",
      "sample_inf処理時間 :  11.6 秒\n"
     ]
    }
   ],
   "source": [
    "inference(cfg.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
